import streamlit as st
import pandas as pd
import requests
from collections import Counter
from datetime import datetime
from xml.etree import ElementTree

# -----------------------------
# 1ï¸âƒ£ é¡µé¢é…ç½®
# -----------------------------
st.set_page_config(page_title="Nova æŠ•è¡Œçº§ç©¿é€çœ‹æ¿ (ç¨³å®šç‰ˆ)", page_icon="ğŸ›¡ï¸", layout="wide")
st.title("ğŸ›¡ï¸ æŠ•è¡Œçº§æ–°é—»æ¿å—ç©¿é€ç³»ç»Ÿ")
st.caption(f"ç³»ç»Ÿæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | æ¨¡å¼: é•œåƒæµ+ä¸é™æµè¡Œæƒ…")

# -----------------------------
# 2ï¸âƒ£ æ ¸å¿ƒæ•°æ®å­—å…¸ (å…³è”è¯ç°‡ + æ ¸å¿ƒæƒé‡è‚¡)
# -----------------------------
# å¢åŠ  keywords ç”¨äºä¸»åŠ¨æœç´¢é•œåƒï¼Œå¢åŠ  stocks ç”¨äºä¸é™æµè¡Œæƒ…å±•ç¤º
SECTOR_CONFIG = {
    "åŒ»è¯": {"keywords": "åŒ»è¯+ç”Ÿç‰©+åˆ›æ–°è¯+é›†é‡‡", "stocks": ["600276", "300760", "603259"]},
    "æ–°èƒ½æº": {"keywords": "é”‚ç”µ+å®å¾·æ—¶ä»£+å‚¨èƒ½+å…‰ä¼", "stocks": ["300750", "002594", "300274"]},
    "ç§‘æŠ€": {"keywords": "åŠå¯¼ä½“+èŠ¯ç‰‡+åä¸º+AI", "stocks": ["603501", "688981", "002415"]},
    "ä½ç©ºç»æµ": {"keywords": "æ— äººæœº+é£è¡Œæ±½è½¦+eVTOL+ç©ºç®¡", "stocks": ["002085", "000099", "600677"]},
    "åŒ–å·¥": {"keywords": "åŒ–å·¥+æ¶¨ä»·+ææ–™+äº§èƒ½", "stocks": ["600309", "002493", "600096"]},
    "ç»¼åˆ/é‡ç»„": {"keywords": "å¹¶è´­+é‡ç»„+é‡ç»„+è‚¡æƒè½¬è®©", "stocks": ["600104", "000157", "600606"]}
}

# -----------------------------
# 3ï¸âƒ£ ä¸é™æµä¸ªè‚¡è¡Œæƒ…æ¥å£ (æ–°æµªè´¢ç»ä¿åº•)
# -----------------------------
@st.cache_data(ttl=60)
def get_realtime_stocks(sector_name):
    """åˆ©ç”¨æ–°æµªè´¢ç» HTML æ¥å£ï¼Œè§„é¿ä¸œè´¢ JSON é™æµ"""
    stock_ids = SECTOR_CONFIG.get(sector_name, {}).get("stocks", ["600519"])
    # æ„é€ æ–°æµªæ ¼å¼ sh600276,sz300760
    formatted_ids = ",".join([f"sh{s}" if s.startswith('6') else f"sz{s}" for s in stock_ids])
    url = f"http://hq.sinajs.cn/list={formatted_ids}"
    
    try:
        # æ–°æµªéœ€è¦ Referer ä¼ªè£…
        headers = {"Referer": "http://finance.sina.com.cn", "User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers, timeout=5).text
        
        data = []
        for line in res.splitlines():
            if '"' in line:
                parts = line.split('"')[1].split(',')
                if len(parts) > 4:
                    name, price, prev_close = parts[0], float(parts[3]), float(parts[2])
                    change = (price - prev_close) / prev_close * 100
                    data.append({"åç§°": name, "æœ€æ–°ä»·": f"{price:.2f}", "æ¶¨è·Œå¹…": f"{change:+.2f}%"})
        return pd.DataFrame(data)
    except:
        return pd.DataFrame()

# -----------------------------
# 4ï¸âƒ£ ä¸»åŠ¨è”åŠ¨æŠ“å–æ–°é—» (è§£å†³â€œæ²¡æ–°é—»â€é—®é¢˜)
# -----------------------------
@st.cache_data(ttl=300)
def fetch_news_via_mirror(query=""):
    """
    è”åŠ¨é€»è¾‘ï¼šä¸å†è¢«åŠ¨ç­‰å¾…ï¼Œè€Œæ˜¯æ ¹æ®æ¿å— query ä¸»åŠ¨è¯·æ±‚ Google/é•œåƒ RSS
    """
    try:
        # æœç´¢ç»„åˆï¼šè´¢è”ç¤¾ + æ¿å—æ ¸å¿ƒè¯
        search_query = f"è´¢è”ç¤¾+{query}"
        url = f"https://news.google.com/rss/search?q={search_query}&hl=zh-CN&gl=CN&ceid=CN:zh-Hans"
        headers = {"User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers, timeout=10)
        root = ElementTree.fromstring(res.content)
        records = []
        for item in root.findall('.//item')[:15]:
            records.append({
                "title": item.find('title').text,
                "time": item.find('pubDate').text,
                "link": item.find('link').text
            })
        return pd.DataFrame(records)
    except:
        return pd.DataFrame()

# =========================
# 5ï¸âƒ£ Streamlit UI äº¤äº’
# =========================
# ä¾§è¾¹æ 
st.sidebar.header("ğŸ” å®¡è®¡æœç´¢")
manual_key = st.sidebar.text_input("æ³¨å…¥æ‰‹åŠ¨å…³é”®è¯", placeholder="å¦‚ï¼šå›è´­")

# å…¨é‡æ—©ç›˜æµ (é»˜è®¤åŠ è½½)
all_news = fetch_news_via_mirror("å¹¶è´­+å›è´­+IPO")

# UI ç¬¬ä¸€éƒ¨åˆ†ï¼šæ¿å—æ·±åº¦ç©¿é€
st.subheader("ğŸ­ æ¿å—æ·±åº¦ç©¿é€")
selected_sector = st.selectbox("é€‰æ‹©å®¡è®¡æ¿å—", list(SECTOR_CONFIG.keys()))

col1, col2 = st.columns([1, 2])

with col1:
    st.write(f"ğŸ“Š **{selected_sector}** ä¸é™æµæƒé‡è¡¨ç°ï¼š")
    stock_df = get_realtime_stocks(selected_sector)
    if not stock_df.empty:
        st.table(stock_df)
    else:
        st.info("æ•°æ®æ¥å£åŒæ­¥ä¸­...")

with col2:
    st.write(f"ğŸ“° **{selected_sector}** è”åŠ¨é•œåƒæ–°é—»ï¼š")
    # è·å–è¯¥æ¿å—å¯¹åº”çš„æœç´¢å…³é”®è¯
    q = SECTOR_CONFIG[selected_sector]["keywords"]
    sector_news = fetch_news_via_mirror(q)
    
    if not sector_news.empty:
        for _, row in sector_news.iterrows():
            with st.expander(f"{row['title']}"):
                st.caption(f"å‘å¸ƒæ—¶é—´: {row['time']}")
                st.markdown(f"[æŸ¥çœ‹ç©¿é€åŸæ–‡]({row['link']})")
    else:
        st.warning(f"å½“å‰é•œåƒæµæš‚æœªå‘ç°ä¸ {selected_sector} ç›¸å…³çš„å¼ºç‰¹å¾çº¿ç´¢ã€‚")

st.divider()

# UI ç¬¬äºŒéƒ¨åˆ†ï¼šçƒ­è¯ä¸å…¨é‡æµ
st.subheader("ğŸ”¥ å®æ—¶æ—©ç›˜å®¡è®¡æµ")
if not all_news.empty:
    for _, row in all_news.head(10).iterrows():
        st.write(f"â— {row['title']} (_{row['time']}_)")
else:
    st.error("æ— æ³•å»ºç«‹å®‰å…¨è¿æ¥ï¼Œé•œåƒæµå—é™ã€‚")

st.markdown("---")
st.caption("Nova å®¡è®¡è„šæ³¨ï¼šä¸ªè‚¡è¡Œæƒ…é‡‡ç”¨æ–°æµª HTML é€šé“ï¼Œæ–°é—»é‡‡ç”¨ä¸»åŠ¨å¼å…³é”®è¯è”åŠ¨é•œåƒã€‚")
