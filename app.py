import streamlit as st
import pandas as pd
import requests
from datetime import datetime
import re

# -----------------------------
# 1ï¸âƒ£ é¡µé¢é…ç½®
# -----------------------------
st.set_page_config(page_title="Nova æŠ•è¡Œçº§ç©¿é€çœ‹æ¿", page_icon="ğŸ›¡ï¸", layout="wide")
st.title("ğŸ›¡ï¸ æŠ•è¡Œçº§æ–°é—»æ¿å—ç©¿é€ç³»ç»Ÿ")
st.caption(f"ç³»ç»Ÿæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | æ¨¡å¼: æ–°æµªå®æ—¶æœç´¢ç©¿é€ (7D)")

# -----------------------------
# 2ï¸âƒ£ æ ¸å¿ƒæ•°æ®å­—å…¸
# -----------------------------
SECTOR_CONFIG = {
    "åŒ»è¯": {"keywords": "åŒ»è¯,åˆ›æ–°è¯,300760", "stocks": ["600276", "300760", "603259"]},
    "æ–°èƒ½æº": {"keywords": "é”‚ç”µ,å®å¾·æ—¶ä»£,å›ºæ€ç”µæ± ", "stocks": ["300750", "002594", "300274"]},
    "æœºå™¨äºº": {"keywords": "æœºå™¨äºº,äººå½¢æœºå™¨äºº,å‡é€Ÿå™¨,002031", "stocks": ["002031", "300024", "603728"]},
    "ç§‘æŠ€": {"keywords": "åŠå¯¼ä½“,èŠ¯ç‰‡,AIç®—åŠ›", "stocks": ["603501", "688981", "002415"]},
    "ç»¼åˆ/é‡ç»„": {"keywords": "å¹¶è´­é‡ç»„,è‚¡æƒè½¬è®©,å¸‚å€¼ç®¡ç†", "stocks": ["600104", "000157", "600606"]},
    "åœ°äº§": {"keywords": "æˆ¿åœ°äº§,æ”¶å‚¨,æˆ¿è´·åˆ©ç‡", "stocks": ["600048", "000002", "601155"]}
}

# -----------------------------
# 3ï¸âƒ£ æ–°æµªå®æ—¶æœç´¢å¼•æ“ (æ ¸å¿ƒæ›¿æ¢ï¼šè§£å†³â€œæ— å†…å®¹â€é—®é¢˜)
# -----------------------------
@st.cache_data(ttl=120)
def fetch_sina_search_live(query):
    """
    æš´åŠ›ç©¿é€ï¼šé€šè¿‡æ–°æµªæœç´¢æ¥å£ç›´æ¥è·å– 7 å¤©å†…çš„å®æ—¶æ–°é—»ä¸å¾®åšå¼‚åŠ¨
    """
    records = []
    # æ‹†åˆ†å…³é”®è¯ä»¥å¢åŠ å‘½ä¸­ç‡
    kws = query.replace("OR", ",").split(",")
    for kw in kws:
        kw = kw.strip()
        url = f"https://search.sina.com.cn/api/search/api.php?q={kw}&refer=f_weibo&f_type=news&s_type=all"
        try:
            headers = {"User-Agent": "Mozilla/5.0"}
            res = requests.get(url, headers=headers, timeout=5).json()
            items = res.get("data", {}).get("list", [])
            for item in items:
                # æ¸…æ´— HTML æ ‡ç­¾
                title = re.sub('<[^<]+?>', '', item.get("title", ""))
                records.append({
                    "title": title,
                    "time": item.get("datetime", "åˆšåˆš"),
                    "link": item.get("url", ""),
                    "source": item.get("source", "å®æ—¶æµ")
                })
        except:
            continue
    
    df = pd.DataFrame(records)
    if not df.empty:
        df = df.drop_duplicates(subset=['title']).sort_values(by='time', ascending=False)
    return df

# -----------------------------
# 4ï¸âƒ£ è¡Œæƒ…å¼•æ“
# -----------------------------
@st.cache_data(ttl=60)
def get_realtime_stocks(sector_name):
    stock_ids = SECTOR_CONFIG.get(sector_name, {}).get("stocks", ["600519"])
    formatted_ids = ",".join([f"sh{s}" if s.startswith('6') else f"sz{s}" for s in stock_ids])
    url = f"http://hq.sinajs.cn/list={formatted_ids}"
    try:
        headers = {"Referer": "http://finance.sina.com.cn", "User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers, timeout=5).text
        data = []
        for line in res.splitlines():
            if '"' in line:
                p = line.split('"')[1].split(',')
                if len(p) > 4:
                    name, price, prev_close = p[0], float(p[3]), float(p[2])
                    change = (price - prev_close) / prev_close * 100
                    data.append({"åç§°": name, "æœ€æ–°ä»·": f"{price:.2f}", "æ¶¨è·Œå¹…": f"{change:+.2f}%"})
        return pd.DataFrame(data)
    except:
        return pd.DataFrame()

# =========================
# 5ï¸âƒ£ UI äº¤äº’å±‚
# =========================
st.sidebar.header("ğŸ” ä¸“é¡¹ç©¿é€")
manual_key = st.sidebar.text_input("æ³¨å…¥æ‰‹åŠ¨å…³é”®è¯/ä»£ç ", placeholder="å¦‚: æœºå™¨äºº")
probe_trigger = st.sidebar.button("ğŸš€ æ‰§è¡Œæš´åŠ›æ¢æµ‹", use_container_width=True)

if probe_trigger and manual_key:
    st.subheader(f"âš¡ 7D ä¸“é¡¹æ¢æµ‹ï¼š{manual_key}")
    res_df = fetch_sina_search_live(manual_key)
    if not res_df.empty:
        for _, r in res_df.iterrows():
            c1, c2 = st.columns([5, 1])
            with c1: 
                st.write(f"â— {r['title']}")
                st.caption(f"ğŸ•’ {r['time']} | æ¥æº: {r['source']}")
            with c2: st.link_button("ç©¿é€", r['link'], key=f"m_{r['link']}")
    else:
        st.error("æ–°æµªæ¥å£æ¢æµ‹å¤±è´¥ï¼Œè¯·å°è¯•è¾“å…¥ä¸ªè‚¡ä»£ç ï¼ˆå¦‚ 002031ï¼‰")
    if st.button("â¬…ï¸ è¿”å›"): st.rerun()

else:
    st.subheader("ğŸ­ æ¿å—æ·±åº¦ç©¿é€")
    selected_sector = st.selectbox("å®¡è®¡æ¿å—", list(SECTOR_CONFIG.keys()))
    col1, col2 = st.columns([1, 2])

    with col1:
        st.write("ğŸ“Š **å®æ—¶è¡Œæƒ…**")
        st.table(get_realtime_stocks(selected_sector))

    with col2:
        st.write(f"ğŸ“° **{selected_sector}** 7D å…³é”®åŠ¨æ€")
        q = SECTOR_CONFIG[selected_sector]["keywords"]
        df_news = fetch_sina_search_live(q)
        if not df_news.empty:
            for _, r in df_news.head(15).iterrows():
                st.write(f"â— {r['title']}")
                st.caption(f"ğŸ•’ {r['time']}")
        else:
            st.warning("å¹¶æœªå‘ç°ç¬æ—¶åŠ¨æ€ï¼Œç³»ç»Ÿæ­£åœ¨é‡è¯•é”šç‚¹ç©¿é€...")

st.divider()
st.subheader("ğŸ”¥ å¸‚åœºå…¨å±€å¼‚åŠ¨æµ (7D)")
global_news = fetch_sina_search_live("å¹¶è´­é‡ç»„,å¼‚åŠ¨,æ¶¨ä»·")
if not global_news.empty:
    for _, r in global_news.head(10).iterrows():
        gc1, gc2 = st.columns([5, 1])
        with gc1: st.write(f"ğŸ“Œ {r['title']} (_{r['time']}_)")
        with gc2: st.link_button("åŸæ–‡", r['link'], key=f"g_{r['link']}")

st.markdown("---")
st.caption("Nova å®¡è®¡è„šæ³¨ï¼šå·²åˆ‡æ¢è‡³æ–°æµª Search å®æ—¶é€šé“ã€‚å¦‚ä»æ— ç»“æœï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ›´æ¢å…³é”®è¯ã€‚")
