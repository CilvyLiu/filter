import streamlit as st
import pandas as pd
import requests
from collections import Counter
from datetime import datetime, timedelta
from xml.etree import ElementTree

# -----------------------------
# 1ï¸âƒ£ é¡µé¢é…ç½®
# -----------------------------
st.set_page_config(page_title="Nova æŠ•è¡Œçº§ç©¿é€çœ‹æ¿", page_icon="ğŸ›¡ï¸", layout="wide")
st.title("ğŸ›¡ï¸ æŠ•è¡Œçº§æ–°é—»æ¿å—ç©¿é€ç³»ç»Ÿ")
st.caption(f"ç³»ç»Ÿæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | æ¨¡å¼: 7å¤©æ·±åº¦ç©¿é€ + ç¤¾äº¤æƒ…ç»ªçŸ©é˜µ")

# -----------------------------
# 2ï¸âƒ£ æ ¸å¿ƒæ•°æ®å­—å…¸ (çƒ­è¯é€»è¾‘ä¼˜åŒ–ï¼šOR å‘½ä¸­æ¨¡å¼)
# -----------------------------
SECTOR_CONFIG = {
    "åŒ»è¯": {"keywords": "åŒ»è¯ OR ç”Ÿç‰© OR åˆ›æ–°è¯ OR é›†é‡‡ OR åŒ»ç–—", "stocks": ["600276", "300760", "603259"]},
    "æ–°èƒ½æº": {"keywords": "é”‚ç”µ OR å®å¾·æ—¶ä»£ OR å‚¨èƒ½ OR å…‰ä¼ OR å›ºæ€ç”µæ± ", "stocks": ["300750", "002594", "300274"]},
    "ç§‘æŠ€": {"keywords": "åŠå¯¼ä½“ OR èŠ¯ç‰‡ OR åä¸º OR AI OR ç®—åŠ›", "stocks": ["603501", "688981", "002415"]},
    "ä½ç©ºç»æµ": {"keywords": "æ— äººæœº OR é£è¡Œæ±½è½¦ OR eVTOL OR ä½ç©ºç»æµ", "stocks": ["002085", "000099", "600677"]},
    "åŒ–å·¥": {"keywords": "åŒ–å·¥ OR æ¶¨ä»· OR äº§èƒ½ OR åŒ–çº¤ OR ç£·åŒ–å·¥", "stocks": ["600309", "002493", "600096"]},
    "ç»¼åˆ/é‡ç»„": {"keywords": "å¹¶è´­ OR é‡ç»„ OR è‚¡æƒè½¬è®© OR å€Ÿå£³ OR å¸‚å€¼ç®¡ç†", "stocks": ["600104", "000157", "600606"]},
    "åœ°äº§": {"keywords": "æˆ¿åœ°äº§ OR æ”¶å‚¨ OR å­˜é‡æˆ¿ OR æˆ¿è´· OR åŸä¸­æ‘", "stocks": ["600048", "000002", "601155"]}
}

# -----------------------------
# 3ï¸âƒ£ è¡Œæƒ…å¼•æ“ (æ–°æµªå®ç›˜é€šé“)
# -----------------------------
@st.cache_data(ttl=60)
def get_realtime_stocks(sector_name):
    stock_ids = SECTOR_CONFIG.get(sector_name, {}).get("stocks", ["600519"])
    formatted_ids = ",".join([f"sh{s}" if s.startswith('6') else f"sz{s}" for s in stock_ids])
    url = f"http://hq.sinajs.cn/list={formatted_ids}"
    try:
        headers = {"Referer": "http://finance.sina.com.cn", "User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers, timeout=5).text
        data = []
        for line in res.splitlines():
            if '"' in line:
                p = line.split('"')[1].split(',')
                if len(p) > 4:
                    name, price, prev_close = p[0], float(p[3]), float(p[2])
                    change = (price - prev_close) / prev_close * 100
                    data.append({"åç§°": name, "æœ€æ–°ä»·": f"{price:.2f}", "æ¶¨è·Œå¹…": f"{change:+.2f}%"})
        return pd.DataFrame(data)
    except:
        return pd.DataFrame()

# -----------------------------
# 4ï¸âƒ£ æ ¸å¿ƒæ¢æµ‹å¼•æ“ (ç©¿é€æ·±åº¦ï¼š7å¤©)
# -----------------------------
@st.cache_data(ttl=300)
def fetch_nova_engine(query="", is_social=False):
    """
    Nova éŸ§æ€§å¼•æ“ï¼šæ”¯æŒ 7å¤© æ·±åº¦ç©¿é€ï¼Œé‡‡ç”¨ OR é€»è¾‘ç»•è¿‡é•œåƒè¿‡æ»¤
    """
    try:
        if is_social:
            # æƒ…ç»ªæ¢æµ‹ï¼šæ‰©å……æ·±åº¦ï¼ŒåŠ å…¥çƒ­é—¨è®¨è®ºæº
            search_query = f"(é›ªçƒ OR è‚¡å§ OR è®¨è®º) {query} after:7d"
        else:
            # å®˜æ–¹æ–°é—»ï¼šæ‰©å……æƒé‡æºï¼Œä¿è¯ä¸è½ç©º
            search_query = f"(è´¢è”ç¤¾ OR è¯åˆ¸æ—¶æŠ¥ OR ç•Œé¢æ–°é—» OR ç¬¬ä¸€è´¢ç») {query} after:7d"
            
        url = f"https://news.google.com/rss/search?q={search_query}&hl=zh-CN&gl=CN&ceid=CN:zh-Hans"
        res = requests.get(url, timeout=10)
        root = ElementTree.fromstring(res.content)
        records = []
        for item in root.findall('.//item')[:15]:
            title = item.find('title').text
            # åŸºç¡€è¿‡æ»¤ï¼Œä¿ç•™æ ¸å¿ƒ
            records.append({
                "title": title.split('-')[0].strip(),
                "time": item.find('pubDate').text,
                "link": item.find('link').text,
                "source": "ğŸ”¥ ç¤¾äº¤/å¼‚åŠ¨" if is_social else "ğŸ“° å®˜æ–¹ä¿¡æº"
            })
        return pd.DataFrame(records)
    except:
        return pd.DataFrame()

# =========================
# 5ï¸âƒ£ Streamlit UI äº¤äº’
# =========================

# ä¾§è¾¹æ 
st.sidebar.header("ğŸ” å®¡è®¡æœç´¢æ§åˆ¶å°")
manual_key = st.sidebar.text_input("æ³¨å…¥æ‰‹åŠ¨å…³é”®è¯", placeholder="å¦‚ï¼šå›ºæ€ç”µæ±  / æœºå™¨äºº")
probe_trigger = st.sidebar.button("ğŸš€ æ‰§è¡Œ 7å¤© å…¨é‡æ¢æµ‹", use_container_width=True)
st.sidebar.divider()

if probe_trigger and manual_key:
    # Aæ¨¡å¼ï¼šä¸»åŠ¨æœç´¢
    st.subheader(f"âš¡ 7D ä¸“é¡¹æ¢æµ‹ï¼š{manual_key}")
    c1, c2 = st.columns(2)
    with c1:
        st.write("ğŸ“– **å®˜æ–¹åŠ¨æ€ç©¿é€**")
        m_news = fetch_nova_engine(manual_key, is_social=False)
        if not m_news.empty:
            for _, r in m_news.iterrows():
                st.write(f"â— {r['title']}")
                st.link_button("ç©¿é€åŸæ–‡", r['link'], key=f"n_{r['link']}")
        else: st.info("æœ¬å‘¨å®˜æ–¹ä¿¡æºæš‚æ— å¼ºåŒ¹é…å†…å®¹")
    with c2:
        st.write("ğŸ§  **ç¤¾äº¤èˆ†æƒ…ç©¿é€**")
        s_news = fetch_nova_engine(manual_key, is_social=True)
        if not s_news.empty:
            for _, r in s_news.iterrows():
                st.write(f"â— {r['title']}")
                st.link_button("æŸ¥çœ‹è®¨è®º", r['link'], key=f"s_{r['link']}")
        else: st.info("æœ¬å‘¨è®¨è®ºçƒ­åº¦å¹³ç¨³")
    if st.button("â¬…ï¸ é‡ç½®çœ‹æ¿è§†å›¾"): st.rerun()

else:
    # Bæ¨¡å¼ï¼šé»˜è®¤çœ‹æ¿æ¨¡å¼
    st.subheader("ğŸ­ æ¿å—æ·±åº¦ç©¿é€ (æœ¬å‘¨å…¨é‡)")
    selected_sector = st.selectbox("é€‰æ‹©å®¡è®¡æ¿å—", list(SECTOR_CONFIG.keys()))
    col1, col2 = st.columns([1, 2])

    with col1:
        st.write(f"ğŸ“Š **{selected_sector}** å®æ—¶è¡Œæƒ…")
        stock_df = get_realtime_stocks(selected_sector)
        if not stock_df.empty:
            st.table(stock_df)
        else: st.info("è¡Œæƒ…åˆ·æ–°ä¸­...")

    with col2:
        st.write(f"ğŸ“° **{selected_sector}** å‘¨å†…å…³é”®åŠ¨æ€")
        q_words = SECTOR_CONFIG[selected_sector]["keywords"]
        sector_news = fetch_nova_engine(q_words, is_social=False)
        if not sector_news.empty:
            for _, row in sector_news.iterrows():
                nc1, nc2 = st.columns([4, 1])
                with nc1:
                    st.write(f"â— {row['title']}")
                    st.caption(f"ğŸ•’ {row['time']}")
                with nc2:
                    st.link_button("ğŸš€ ç©¿é€", row['link'], use_container_width=True)
        else: st.warning("ğŸ’¡ æœ¬å‘¨æš‚æ— æ·±åº¦å…³è”åŠ¨æ€ã€‚å»ºè®®åœ¨ä¾§è¾¹æ æ‰‹åŠ¨æ³¨å…¥å…·ä½“ä»£ç ç©¿é€ã€‚")

    st.divider()
    # ç¤¾äº¤æƒ…ç»ªæ¨¡å—
    st.subheader(f"ğŸ§  {selected_sector} ç¤¾äº¤çƒ­è®®/ä¼ é—»æ¢æµ‹ (7D)")
    sentiment_df = fetch_nova_engine(selected_sector, is_social=True)
    if not sentiment_df.empty:
        scs = st.columns(2)
        for i, (_, row) in enumerate(sentiment_df.iterrows()):
            with scs[i % 2]:
                st.info(f"{row['title']}")
                st.link_button("è¿›å…¥ç¤¾åŒºè®¨è®º", row['link'], use_container_width=True)
    else: st.write("æœ¬å‘¨æ¿å—ç¤¾äº¤è®¨è®ºå¤„äºå¸¸æ€åŒºé—´ã€‚")

st.divider()

# 2. å…¨é‡æµï¼ˆå¸¸é©»åº•éƒ¨ï¼‰
st.subheader("ğŸ”¥ å¸‚åœºå…¨å±€å¼‚åŠ¨æµ (7D)")
main_news = fetch_nova_engine("(å¹¶è´­ OR é‡ç»„ OR å›è´­ OR å¼‚åŠ¨ OR æ¶¨ä»·)", is_social=False)
if not main_news.empty:
    for _, row in main_news.head(15).iterrows():
        mc1, mc2 = st.columns([5, 1])
        with mc1:
            st.write(f"ğŸ“Œ {row['title']} (_{row['time']}_)")
        with mc2:
            st.link_button("åŸæ–‡", row['link'], key=f"main_{row['link']}")

st.markdown("---")
st.caption("Nova å®¡è®¡è„šæ³¨ï¼šé‡‡ç”¨ after:7d æ·±åº¦ç´¢å¼•ï¼Œé€»è¾‘å±‚å·²å¼ºåˆ¶ä¼˜åŒ–å…³é”®è¯å‘½ä¸­è§„åˆ™ã€‚")
