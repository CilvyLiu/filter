import streamlit as st
import pandas as pd
import requests
from collections import Counter
from datetime import datetime
from xml.etree import ElementTree

# -----------------------------
# 1ï¸âƒ£ é¡µé¢é…ç½®
# -----------------------------
st.set_page_config(page_title="Nova æŠ•è¡Œçº§ç©¿é€çœ‹æ¿", page_icon="ğŸ›¡ï¸", layout="wide")
st.title("ğŸ›¡ï¸ æŠ•è¡Œçº§æ–°é—»æ¿å—ç©¿é€ç³»ç»Ÿ")
st.caption(f"ç³»ç»Ÿæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | æ¨¡å¼: è”åŠ¨é•œåƒ+ä¸»åŠ¨æ¢æµ‹")

# -----------------------------
# 2ï¸âƒ£ æ ¸å¿ƒæ•°æ®å­—å…¸
# -----------------------------
SECTOR_CONFIG = {
    "åŒ»è¯": {"keywords": "åŒ»è¯+ç”Ÿç‰©+åˆ›æ–°è¯+é›†é‡‡", "stocks": ["600276", "300760", "603259"]},
    "æ–°èƒ½æº": {"keywords": "é”‚ç”µ+å®å¾·æ—¶ä»£+å‚¨èƒ½+å…‰ä¼", "stocks": ["300750", "002594", "300274"]},
    "ç§‘æŠ€": {"keywords": "åŠå¯¼ä½“+èŠ¯ç‰‡+åä¸º+AI", "stocks": ["603501", "688981", "002415"]},
    "ä½ç©ºç»æµ": {"keywords": "æ— äººæœº+é£è¡Œæ±½è½¦+eVTOL", "stocks": ["002085", "000099", "600677"]},
    "åŒ–å·¥": {"keywords": "åŒ–å·¥+æ¶¨ä»·+ææ–™+äº§èƒ½", "stocks": ["600309", "002493", "600096"]},
    "ç»¼åˆ/é‡ç»„": {"keywords": "å¹¶è´­+é‡ç»„+é‡ç»„+è‚¡æƒè½¬è®©", "stocks": ["600104", "000157", "600606"]},
    "åœ°äº§": {"keywords": "æˆ¿åœ°äº§+æ”¶å‚¨+å­˜é‡æˆ¿+æˆ¿è´·", "stocks": ["600048", "000002", "601155"]}
}

# -----------------------------
# 3ï¸âƒ£ ä¸é™æµä¸ªè‚¡è¡Œæƒ…æ¥å£
# -----------------------------
@st.cache_data(ttl=60)
def get_realtime_stocks(sector_name):
    stock_ids = SECTOR_CONFIG.get(sector_name, {}).get("stocks", ["600519"])
    formatted_ids = ",".join([f"sh{s}" if s.startswith('6') else f"sz{s}" for s in stock_ids])
    url = f"http://hq.sinajs.cn/list={formatted_ids}"
    try:
        headers = {"Referer": "http://finance.sina.com.cn", "User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers, timeout=5).text
        data = []
        for line in res.splitlines():
            if '"' in line:
                p = line.split('"')[1].split(',')
                if len(p) > 4:
                    name, price, prev_close = p[0], float(p[3]), float(p[2])
                    change = (price - prev_close) / prev_close * 100
                    data.append({"åç§°": name, "æœ€æ–°ä»·": f"{price:.2f}", "æ¶¨è·Œå¹…": f"{change:+.2f}%"})
        return pd.DataFrame(data)
    except:
        return pd.DataFrame()

# -----------------------------
# 4ï¸âƒ£ æ ¸å¿ƒæŠ“å–å¼•æ“
# -----------------------------
@st.cache_data(ttl=300)
def fetch_news_via_mirror(query=""):
    try:
        search_query = f"è´¢è”ç¤¾+{query}"
        url = f"https://news.google.com/rss/search?q={search_query}&hl=zh-CN&gl=CN&ceid=CN:zh-Hans"
        res = requests.get(url, timeout=10)
        root = ElementTree.fromstring(res.content)
        records = []
        for item in root.findall('.//item')[:15]:
            records.append({
                "title": item.find('title').text,
                "time": item.find('pubDate').text,
                "link": item.find('link').text
            })
        return pd.DataFrame(records)
    except:
        return pd.DataFrame()

# =========================
# 5ï¸âƒ£ Streamlit UI äº¤äº’
# =========================

# ä¾§è¾¹æ ï¼šæ¢æµ‹æ§åˆ¶
st.sidebar.header("ğŸ” å®¡è®¡æœç´¢æ§åˆ¶å°")
manual_key = st.sidebar.text_input("æ³¨å…¥æ‰‹åŠ¨å…³é”®è¯", placeholder="å¦‚ï¼šå¸‚å€¼ç®¡ç† / å›ºæ€ç”µæ± ")
probe_trigger = st.sidebar.button("ğŸš€ æ‰§è¡Œç©¿é€æ¢æµ‹", use_container_width=True)
st.sidebar.divider()

# --- ä¸»å±é€»è¾‘åˆ‡æ¢ ---

# Aæ¨¡å¼ï¼šä¸»åŠ¨æ¢æµ‹æ¨¡å¼ï¼ˆå½“ç”¨æˆ·ç‚¹å‡»æ¢æµ‹æŒ‰é’®ä¸”æœ‰è¾“å…¥æ—¶ï¼‰
if probe_trigger and manual_key:
    st.subheader(f"ğŸš€ ä¸“é¡¹æœç´¢ï¼š{manual_key}")
    with st.spinner(f"æ­£åœ¨ç©¿é€é•œåƒæºæŠ“å– '{manual_key}' ç›¸å…³çº¿ç´¢..."):
        manual_news = fetch_news_via_mirror(manual_key)
    
    if not manual_news.empty:
        for _, row in manual_news.iterrows():
            c1, c2 = st.columns([5, 1])
            with c1:
                st.markdown(f"**{row['title']}**")
                st.caption(f"â³ {row['time']}")
            with c2:
                st.link_button("ç©¿é€å…¨æ–‡", row['link'], use_container_width=True)
            st.divider()
        if st.button("â¬…ï¸ é‡ç½®çœ‹æ¿è§†å›¾"):
            st.rerun()
    else:
        st.warning(f"æœªèƒ½å‘ç°ä¸ '{manual_key}' ç›¸å…³çš„çªå‘æƒ…æŠ¥ã€‚")

# Bæ¨¡å¼ï¼šé»˜è®¤çœ‹æ¿æ¨¡å¼
else:
    # 1. æ¿å—æ·±åº¦ç©¿é€
    st.subheader("ğŸ­ æ¿å—æ·±åº¦ç©¿é€")
    selected_sector = st.selectbox("é€‰æ‹©å®¡è®¡æ¿å—", list(SECTOR_CONFIG.keys()))

    col1, col2 = st.columns([1, 2])

    with col1:
        st.write(f"ğŸ“Š **{selected_sector}** å®æ—¶è¡Œæƒ…ï¼š")
        stock_df = get_realtime_stocks(selected_sector)
        if not stock_df.empty:
            st.table(stock_df)
        else:
            st.info("è¡Œæƒ…æ¥å£åŒæ­¥ä¸­...")

    with col2:
        st.write(f"ğŸ“° **{selected_sector}** æ¿å—å…³è”åŠ¨æ€ï¼š")
        q_words = SECTOR_CONFIG[selected_sector]["keywords"]
        sector_news = fetch_news_via_mirror(q_words)
        
        if not sector_news.empty:
            for _, row in sector_news.iterrows():
                # æ”¹ä¸ºå¹³é“ºæ˜¾ç¤ºï¼Œå¢åŠ æ‰«ææ•ˆç‡
                nc1, nc2 = st.columns([4, 1])
                with nc1:
                    st.write(f"â— {row['title']}")
                    st.caption(f"_{row['time']}_")
                with nc2:
                    st.link_button("ğŸš€ ç©¿é€", row['link'], use_container_width=True)
        else:
            st.warning(f"ğŸ’¡ æš‚æœªå‘ç°ä¸ {selected_sector} ç›¸å…³çš„å®æ—¶çº¿ç´¢ã€‚")

st.divider()

# 2. å…¨é‡æµï¼ˆå¸¸é©»åº•éƒ¨ï¼‰
st.subheader("ğŸ”¥ å®æ—¶æ—©ç›˜å…¨é‡æµ")
main_news = fetch_news_via_mirror("å¹¶è´­+å›è´­+IPO+å¼‚åŠ¨")
if not main_news.empty:
    for _, row in main_news.head(10).iterrows():
        mc1, mc2 = st.columns([5, 1])
        with mc1:
            st.write(f"ğŸ“Œ {row['title']} (_{row['time']}_)")
        with mc2:
            st.link_button("åŸæ–‡", row['link'])
else:
    st.error("æ•°æ®æµå—é˜»ï¼Œè¯·æ£€æŸ¥ç½‘ç»œç¯å¢ƒã€‚")

st.markdown("---")
st.caption("Nova å®¡è®¡è„šæ³¨ï¼šé‡‡ç”¨é•œåƒè”åŠ¨é€»è¾‘ï¼Œæ‰‹åŠ¨å…³é”®è¯æ”¯æŒå…¨å±€æ¢æµ‹æ¨¡å¼ã€‚")
