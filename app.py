import streamlit as st
import pandas as pd
import requests
from collections import Counter
from datetime import datetime
from xml.etree import ElementTree
import re

# -----------------------------
# 1ï¸âƒ£ é¡µé¢é…ç½®
# -----------------------------
st.set_page_config(page_title="Nova 2026 ç©¿é€çœ‹æ¿", page_icon="ğŸ›¡ï¸", layout="wide")
st.title("ğŸ›¡ï¸ æŠ•è¡Œçº§ 7D å…¨ç½‘ç©¿é€ç³»ç»Ÿ")
st.caption(f"ç³»ç»Ÿæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | æ¨¡å¼: è…¾è®¯è¡Œæƒ…+è´¢è”ç¤¾è¯­ä¹‰ç©¿é€")

# -----------------------------
# 2ï¸âƒ£ 2026 æ ¸å¿ƒæ•°æ®å­—å…¸ (çƒ­è¯é€»è¾‘å¢å¼º)
# -----------------------------
SECTOR_CONFIG = {
    "æœºå™¨äºº/æ™ºé€ ": {"keywords": "(æœºå™¨äºº OR è¡Œæ˜Ÿä¸æ  OR çµå·§æ‰‹ OR å‡é€Ÿå™¨ OR å…·èº«æ™ºèƒ½)", "stocks": ["603728", "300024", "002031"]},
    "AIç®—åŠ›/å°è£…": {"keywords": "(ç»ç’ƒåŸºæ¿ OR HBM4 OR ç®—åŠ›ç§Ÿèµ OR ç¡…å…‰æ¨¡å— OR CPO)", "stocks": ["603501", "688012", "002415"]},
    "å•†ä¸šèˆªå¤©/ä½ç©º": {"keywords": "(eVTOL OR åƒå¸†æ˜Ÿåº§ OR ä½ç©ºç©ºåŸŸ OR å«æ˜Ÿäº’è”ç½‘)", "stocks": ["002085", "600118", "300455"]},
    "åŒ»è¯/ç”Ÿç‰©": {"keywords": "(GLP-1 OR ADCè¯ç‰© OR å‡ºæµ·æˆæƒ OR åˆæˆç”Ÿç‰©)", "stocks": ["600276", "300760", "603259"]},
    "æ–°èƒ½æº/å‚¨èƒ½": {"keywords": "(å…¨å›ºæ€ç”µæ±  OR é’ ç”µæ±  OR æ„ç½‘å‹å‚¨èƒ½ OR é’™é’›çŸ¿)", "stocks": ["300750", "002594", "300274"]},
    "é‡ç»„/ç§‘åˆ›": {"keywords": "(å¹¶è´­é‡ç»„ OR ç§‘åˆ›æ¿å…«æ¡ OR èµ„äº§æ³¨å…¥ OR ä¸¾ç‰Œ OR å€Ÿå£³)", "stocks": ["600104", "000157", "600606"]},
    "åœ°äº§/å®è§‚": {"keywords": "(æ”¶å‚¨ OR å­˜é‡æˆ¿è´· OR æˆ¿åœ°è”åŠ¨ OR ä¸“é¡¹å€º)", "stocks": ["600048", "000002", "601155"]}
}

# -----------------------------
# 3ï¸âƒ£ ç¨³å®šè¡Œæƒ…æ¥å£ï¼šè…¾è®¯ Qt
# -----------------------------
@st.cache_data(ttl=60)
def get_realtime_stocks(sector_name):
    stock_ids = SECTOR_CONFIG.get(sector_name, {}).get("stocks", ["600519"])
    formatted_ids = ",".join([f"sh{s}" if s.startswith('6') else f"sz{s}" for s in stock_ids])
    url = f"http://qt.gtimg.cn/q={formatted_ids}"
    try:
        res = requests.get(url, timeout=5).text
        data = []
        for line in res.splitlines():
            if '~' in line:
                p = line.split('~')
                if len(p) > 32:
                    data.append({
                        "åç§°": p[1], 
                        "æœ€æ–°ä»·": f"{float(p[3]):.2f}", 
                        "æ¶¨è·Œå¹…": f"{float(p[32]):+.2f}%"
                    })
        return pd.DataFrame(data)
    except:
        return pd.DataFrame()

# -----------------------------
# 4ï¸âƒ£ æ ¸å¿ƒæŠ“å–å¼•æ“ï¼šGoogle RSS (7D)
# -----------------------------
@st.cache_data(ttl=600)
def fetch_news_via_google(query=""):
    try:
        search_query = f"({query}) (site:cls.cn OR site:jiemian.com OR site:stcn.com OR site:163.com OR site:qq.com OR site:sina.com.cn)"
        url = f"https://news.google.com/rss/search?q={search_query}+when:7d&hl=zh-CN&gl=CN&ceid=CN:zh-Hans"
        headers = {"User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers, timeout=10)
        root = ElementTree.fromstring(res.content)
        records = []
        for item in root.findall('.//item')[:25]:
            full_title = item.find('title').text
            title = full_title.rsplit(' - ', 1)[0] if ' - ' in full_title else full_title
            source = full_title.rsplit(' - ', 1)[1] if ' - ' in full_title else "å…¨ç½‘"
            records.append({
                "source": source,
                "title": title,
                "time": item.find('pubDate').text[5:16],
                "link": item.find('link').text
            })
        return pd.DataFrame(records)
    except:
        return pd.DataFrame()

# -----------------------------
# 5ï¸âƒ£ çƒ­è¯åˆ†æ (è´¢è”ç¤¾é£æ ¼+Aè‚¡æ·±åº¦æ‰©å±•)
# -----------------------------
def analyze_hot_keywords(df):
    if df.empty: return []
    # æ‰©å±•ï¼šè¿‡æ»¤éå®è´¨æ€§è¯ï¼Œä¿ç•™ A è‚¡æ ¸å¿ƒé¢˜æè¯
    stop_words = [
        "è´¢ç»", "æ–°é—»", "å‘å¸ƒ", "å…¬å¸", "ä¸­å›½", "å¸‚åœº", "æŠ«éœ²", "è¿›è¡Œ", "åˆ†æ", "å…³æ³¨", 
        "ç ”æŠ¥", "è¯åˆ¸", "è¡¨ç¤º", "æœºæ„", "æŒç»­", "æ ¸å¿ƒ", "æ¿å—", "ä¸šåŠ¡", "æ­£å¼", "äº¿å…ƒ"
    ]
    # å¼ºåˆ¶å…³æ³¨è¯ï¼ˆæé«˜æƒé‡ï¼‰
    focus_words = [
        "é‡äº§", "ç ´äº§", "å€Ÿå£³", "é‡ç»„", "è·æ‰¹", "æš´æ¶¨", "é¦–å‘", "è®¢å•", "é—®è¯¢", "æ¶¨åœ"
    ]
    
    text = " ".join(df['title'].tolist())
    # åŒ¹é…ä¸­æ–‡è¯
    words = re.findall(r'[\u4e00-\u9fa5]{2,}', text) 
    
    filtered_words = []
    for w in words:
        if w not in stop_words:
            # å¦‚æœæ˜¯é‡ç‚¹è¯ï¼Œå¢åŠ å‡ºç°æƒé‡
            if w in focus_words:
                filtered_words.extend([w] * 2)
            else:
                filtered_words.append(w)
                
    return Counter(filtered_words).most_common(10)

# =========================
# 6ï¸âƒ£ UI äº¤äº’
# =========================

st.sidebar.header("ğŸ” å®¡è®¡æœç´¢æ§åˆ¶å°")
manual_key = st.sidebar.text_input("æ³¨å…¥æ‰‹åŠ¨å…³é”®è¯", placeholder="å¦‚ï¼šäººå½¢æœºå™¨äºº / èµ„äº§æ³¨å…¥")
probe_trigger = st.sidebar.button("ğŸš€ æ‰§è¡Œç©¿é€æ¢æµ‹", use_container_width=True)
st.sidebar.divider()

if probe_trigger and manual_key:
    st.subheader(f"ğŸš€ ä¸“é¡¹æ¢æµ‹ï¼š{manual_key} (7D)")
    news = fetch_news_via_google(manual_key)
    if not news.empty:
        hot_tags = analyze_hot_keywords(news)
        st.write("ğŸ·ï¸ **åŠ¨æ€çƒ­è¯ç»Ÿè®¡ï¼š** " + " ".join([f"`{w[0]}({w[1]})`" for w in hot_tags]))
        st.dataframe(news, use_container_width=True, hide_index=True)
    else:
        st.warning("æœªèƒ½ç©¿é€ç›¸å…³çº¿ç´¢ã€‚")
else:
    # é»˜è®¤çœ‹æ¿
    st.subheader("ğŸ­ è¡Œä¸šæ·±åº¦ç©¿é€çœ‹æ¿")
    selected_sector = st.selectbox("å®¡è®¡æ¿å—åˆ‡æ¢", list(SECTOR_CONFIG.keys()))
    col1, col2 = st.columns([1, 2.5])

    with col1:
        st.write(f"ğŸ“Š **{selected_sector}** å®æ—¶è¡Œæƒ…ï¼š")
        stock_df = get_realtime_stocks(selected_sector)
        if not stock_df.empty:
            st.table(stock_df)
            
        st.divider()
        st.write("ğŸ“ˆ **èˆ†æƒ…çƒ­ç‚¹è¯äº‘ (è´¢è”ç¤¾é£æ§)**")
        q_words = SECTOR_CONFIG[selected_sector]["keywords"]
        sector_news = fetch_news_via_google(q_words)
        hot_tags = analyze_hot_keywords(sector_news)
        if hot_tags:
            for tag, count in hot_tags:
                st.write(f"Â· {tag}")
                st.progress(min(count * 10, 100))
        else:
            st.caption("æš‚æœªæå–åˆ°è¶³å¤Ÿé¢‘æ¬¡çš„å…³é”®è¯ã€‚")

    with col2:
        st.write(f"ğŸ“° **{selected_sector}** 7D å…³é”®åŠ¨æ€ç©¿é€ï¼š")
        if not sector_news.empty:
            for _, row in sector_news.iterrows():
                with st.container():
                    c_a, c_b = st.columns([5, 1])
                    c_a.markdown(f"**[{row['source']}]** {row['title']}")
                    c_a.caption(f"â³ {row['time']}")
                    c_b.link_button("ç©¿é€", row['link'], use_container_width=True)
                    st.divider()
        else:
            st.warning("âš ï¸ æ¢æµ‹å—é˜»ã€‚")

st.divider()
st.subheader("ğŸ”¥ å¸‚åœºå…¨å±€å¼‚åŠ¨æµ (7Då›æº¯)")
main_news = fetch_news_via_google("å¹¶è´­é‡ç»„ OR è‚¡æƒè½¬è®© OR å¼‚åŠ¨ OR ä¸¾ç‰Œ OR å¯è½¬å€º")
if not main_news.empty:
    st.dataframe(main_news[['time', 'source', 'title']], use_container_width=True, hide_index=True)

st.caption("Nova å®¡è®¡è„šæ³¨ï¼šé‡‡ç”¨è…¾è®¯ Qt + Google 7D é•œåƒç©¿é€ã€‚çƒ­è¯ç»Ÿè®¡å·²æ•´åˆ A è‚¡é¢˜ææ·±åº¦æ¨¡å‹ã€‚")
