import streamlit as st
import pandas as pd
import requests
from datetime import datetime, timedelta
from xml.etree import ElementTree
from email.utils import parsedate_to_datetime

# -----------------------------
# 1ï¸âƒ£ é¡µé¢é…ç½®
# -----------------------------
st.set_page_config(page_title="Nova æŠ•è¡Œçº§ç©¿é€çœ‹æ¿", page_icon="ğŸ›¡ï¸", layout="wide")
st.title("ğŸ›¡ï¸ æŠ•è¡Œçº§æ–°é—»æ¿å—ç©¿é€ç³»ç»Ÿ")
st.caption(f"ç³»ç»Ÿæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | æ¨¡å¼: è‡ªåŠ¨ç©¿é€æ¿å—å…³é”®è¯")

# -----------------------------
# 2ï¸âƒ£ æ ¸å¿ƒæ•°æ®å­—å…¸
# -----------------------------
SECTOR_CONFIG = {
    "åŒ»è¯": {"keywords": ["åŒ»è¯", "ç”Ÿç‰©", "åˆ›æ–°è¯", "é›†é‡‡"], "stocks": ["600276", "300760", "603259"]},
    "æ–°èƒ½æº": {"keywords": ["é”‚ç”µ", "å®å¾·æ—¶ä»£", "å‚¨èƒ½", "å…‰ä¼"], "stocks": ["300750", "002594", "300274"]},
    "ç§‘æŠ€": {"keywords": ["åŠå¯¼ä½“", "èŠ¯ç‰‡", "åä¸º", "AI"], "stocks": ["603501", "688981", "002415"]},
    "ä½ç©ºç»æµ": {"keywords": ["æ— äººæœº", "é£è¡Œæ±½è½¦", "eVTOL"], "stocks": ["002085", "000099", "600677"]},
    "åŒ–å·¥": {"keywords": ["åŒ–å·¥", "æ¶¨ä»·", "ææ–™", "äº§èƒ½"], "stocks": ["600309", "002493", "600096"]},
    "ç»¼åˆ/é‡ç»„": {"keywords": ["å¹¶è´­", "é‡ç»„", "è‚¡æƒè½¬è®©"], "stocks": ["600104", "000157", "600606"]},
    "åœ°äº§": {"keywords": ["æˆ¿åœ°äº§", "æ”¶å‚¨", "å­˜é‡æˆ¿", "æˆ¿è´·"], "stocks": ["600048", "000002", "601155"]}
}

# -----------------------------
# 3ï¸âƒ£ ä¸é™æµä¸ªè‚¡è¡Œæƒ…æ¥å£
# -----------------------------
@st.cache_data(ttl=60)
def get_realtime_stocks(sector_name):
    stock_ids = SECTOR_CONFIG.get(sector_name, {}).get("stocks", ["600519"])
    formatted_ids = ",".join([f"sh{s}" if s.startswith('6') else f"sz{s}" for s in stock_ids])
    url = f"http://hq.sinajs.cn/list={formatted_ids}"
    try:
        headers = {"Referer": "http://finance.sina.com.cn", "User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers, timeout=5).text
        data = []
        for line in res.splitlines():
            if '"' in line:
                p = line.split('"')[1].split(',')
                if len(p) > 4:
                    name, price, prev_close = p[0], float(p[3]), float(p[2])
                    change = (price - prev_close) / prev_close * 100
                    data.append({"åç§°": name, "æœ€æ–°ä»·": f"{price:.2f}", "æ¶¨è·Œå¹…": f"{change:+.2f}%"})
        return pd.DataFrame(data)
    except:
        return pd.DataFrame()

# -----------------------------
# 4ï¸âƒ£ è‡ªåŠ¨æŠ“å–æ¿å—æ–°é—»ï¼ˆæœ€è¿‘7å¤©ï¼‰
# -----------------------------
@st.cache_data(ttl=300)
def fetch_news_for_sector(sector_name, days=7):
    try:
        keywords = SECTOR_CONFIG.get(sector_name, {}).get("keywords", [])
        if not keywords:
            return pd.DataFrame()
        
        records = []
        # é’ˆå¯¹æ¯ä¸ªå…³é”®è¯æŠ“å–
        for kw in keywords:
            search_query = f"è´¢è”ç¤¾ {kw}"
            url = f"https://news.google.com/rss/search?q={search_query}&hl=zh-CN&gl=CN&ceid=CN:zh-Hans"
            res = requests.get(url, timeout=10)
            root = ElementTree.fromstring(res.content)
            for item in root.findall('.//item')[:50]:
                title = item.find('title').text
                pub_date = item.find('pubDate').text
                link = item.find('link').text
                try:
                    pub_dt = parsedate_to_datetime(pub_date)
                except:
                    pub_dt = datetime.utcnow()
                if datetime.utcnow() - pub_dt <= timedelta(days=days):
                    records.append({"title": title, "time": pub_dt, "link": link})
        
        # å»é‡æ ‡é¢˜å¹¶æŒ‰æ—¶é—´æ’åº
        df = pd.DataFrame(records)
        if not df.empty:
            df.drop_duplicates(subset=['title'], inplace=True)
            df.sort_values(by='time', ascending=False, inplace=True)
        return df
    except Exception as e:
        print("æŠ“å–å¤±è´¥:", e)
        return pd.DataFrame()

# =========================
# 5ï¸âƒ£ Streamlit UI äº¤äº’
# =========================
st.sidebar.header("ğŸ” å®¡è®¡æœç´¢æ§åˆ¶å°")
probe_trigger = st.sidebar.button("ğŸš€ æ‰§è¡Œæ¿å—è‡ªåŠ¨ç©¿é€", use_container_width=True)
st.sidebar.divider()

# Bæ¨¡å¼ï¼šæ¿å—é»˜è®¤çœ‹æ¿
st.subheader("ğŸ­ æ¿å—æ·±åº¦ç©¿é€")
selected_sector = st.selectbox("é€‰æ‹©å®¡è®¡æ¿å—", list(SECTOR_CONFIG.keys()))
col1, col2 = st.columns([1, 2])

with col1:
    st.write(f"ğŸ“Š **{selected_sector}** å®æ—¶è¡Œæƒ…ï¼š")
    stock_df = get_realtime_stocks(selected_sector)
    if not stock_df.empty:
        st.table(stock_df)
    else:
        st.info("è¡Œæƒ…æ¥å£åŒæ­¥ä¸­...")

with col2:
    st.write(f"ğŸ“° **{selected_sector}** æ¿å—å…³è”åŠ¨æ€ï¼š")
    if probe_trigger:
        sector_news = fetch_news_for_sector(selected_sector)
        if not sector_news.empty:
            for _, row in sector_news.iterrows():
                nc1, nc2 = st.columns([4, 1])
                with nc1:
                    st.write(f"â— {row['title']}")
                    st.caption(f"_{row['time'].strftime('%Y-%m-%d %H:%M')}_")
                with nc2:
                    st.link_button("ğŸš€ ç©¿é€", row['link'], use_container_width=True)
        else:
            st.warning(f"ğŸ’¡ æš‚æœªå‘ç°ä¸ {selected_sector} ç›¸å…³çš„æœ€æ–°çº¿ç´¢ã€‚")

st.divider()

# å…¨é‡æµ
st.subheader("ğŸ”¥ å®æ—¶æ—©ç›˜å…¨é‡æµ")
main_news = fetch_news_for_sector("ç»¼åˆ/é‡ç»„")
if not main_news.empty:
    for _, row in main_news.head(10).iterrows():
        mc1, mc2 = st.columns([5, 1])
        with mc1:
            st.write(f"ğŸ“Œ {row['title']} (_{row['time'].strftime('%Y-%m-%d %H:%M')}_)")
        with mc2:
            st.link_button("åŸæ–‡", row['link'])
else:
    st.error("æ•°æ®æµå—é˜»æˆ–è¿‘æœŸæ— æ–°æ–°é—»ã€‚")

st.markdown("---")
st.caption("Nova å®¡è®¡è„šæ³¨ï¼šæ–°é—»è‡ªåŠ¨æå–æ¿å—å…³é”®è¯ï¼Œæœ€è¿‘7å¤©å†…ï¼Œå·²å»é‡å¹¶æŒ‰æ—¶é—´æ’åºã€‚")
