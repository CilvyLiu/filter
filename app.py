import streamlit as st
import pandas as pd
import requests
from collections import Counter
from datetime import datetime, timedelta
from xml.etree import ElementTree

# -----------------------------
# 1ï¸âƒ£ é¡µé¢é…ç½®
# -----------------------------
st.set_page_config(page_title="Nova æŠ•è¡Œçº§ç©¿é€çœ‹æ¿", page_icon="ğŸ›¡ï¸", layout="wide")
st.title("ğŸ›¡ï¸ æŠ•è¡Œçº§æ–°é—»æ¿å—ç©¿é€ç³»ç»Ÿ")
st.caption(f"ç³»ç»Ÿæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | æ¨¡å¼: 7å¤©æ·±åº¦ç©¿é€ + ç¤¾äº¤èˆ†æƒ…çŸ©é˜µ")

# -----------------------------
# 2ï¸âƒ£ æ ¸å¿ƒæ•°æ®å­—å…¸ (çƒ­è¯ä¼˜åŒ–ï¼šé‡‡ç”¨ OR é€»è¾‘æé«˜å‘½ä¸­ç‡)
# -----------------------------
SECTOR_CONFIG = {
    "åŒ»è¯": {"keywords": "(åŒ»è¯ OR ç”Ÿç‰© OR åˆ›æ–°è¯ OR é›†é‡‡ OR åŒ»ç–—å™¨æ¢°)", "stocks": ["600276", "300760", "603259"]},
    "æ–°èƒ½æº": {"keywords": "(é”‚ç”µ OR å®å¾·æ—¶ä»£ OR å‚¨èƒ½ OR å…‰ä¼ OR å›ºæ€ç”µæ± )", "stocks": ["300750", "002594", "300274"]},
    "ç§‘æŠ€": {"keywords": "(åŠå¯¼ä½“ OR èŠ¯ç‰‡ OR åä¸º OR AI OR ç®—åŠ›)", "stocks": ["603501", "688981", "002415"]},
    "ä½ç©ºç»æµ": {"keywords": "(æ— äººæœº OR é£è¡Œæ±½è½¦ OR eVTOL OR å•†ä¸šèˆªå¤©)", "stocks": ["002085", "000099", "600677"]},
    "åŒ–å·¥": {"keywords": "(åŒ–å·¥ OR æ¶¨ä»· OR ææ–™ OR äº§èƒ½ OR ç£·åŒ–å·¥)", "stocks": ["600309", "002493", "600096"]},
    "ç»¼åˆ/é‡ç»„": {"keywords": "(å¹¶è´­ OR é‡ç»„ OR è‚¡æƒè½¬è®© OR å€Ÿå£³ OR å¸‚å€¼ç®¡ç†)", "stocks": ["600104", "000157", "600606"]},
    "åœ°äº§": {"keywords": "(æˆ¿åœ°äº§ OR æ”¶å‚¨ OR å­˜é‡æˆ¿ OR æˆ¿è´· OR åŸä¸­æ‘)", "stocks": ["600048", "000002", "601155"]}
}

# -----------------------------
# 3ï¸âƒ£ è¡Œæƒ…å¼•æ“ (æ–°æµªHTMLé€šé“)
# -----------------------------
@st.cache_data(ttl=60)
def get_realtime_stocks(sector_name):
    stock_ids = SECTOR_CONFIG.get(sector_name, {}).get("stocks", ["600519"])
    formatted_ids = ",".join([f"sh{s}" if s.startswith('6') else f"sz{s}" for s in stock_ids])
    url = f"http://hq.sinajs.cn/list={formatted_ids}"
    try:
        headers = {"Referer": "http://finance.sina.com.cn", "User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers, timeout=5).text
        data = []
        for line in res.splitlines():
            if '"' in line:
                p = line.split('"')[1].split(',')
                if len(p) > 4:
                    name, price, prev_close = p[0], float(p[3]), float(p[2])
                    change = (price - prev_close) / prev_close * 100
                    data.append({"åç§°": name, "æœ€æ–°ä»·": f"{price:.2f}", "æ¶¨è·Œå¹…": f"{change:+.2f}%"})
        return pd.DataFrame(data)
    except:
        return pd.DataFrame()

# -----------------------------
# 4ï¸âƒ£ æ ¸å¿ƒæ¢æµ‹å¼•æ“ (æ–°é—»+æƒ…ç»ª)
# -----------------------------
@st.cache_data(ttl=300) # 7å¤©æ•°æ®é‡å¤§ï¼Œå¢åŠ ç¼“å­˜æ—¶é—´
def fetch_nova_engine(query="", is_social=False):
    """
    Nova å¼•æ“ï¼šæ”¯æŒ 7å¤© å¼ºåˆ¶æ–°é—»æ¢æµ‹æˆ–ç¤¾äº¤æƒ…ç»ªæ¢æµ‹
    """
    try:
        if is_social:
            # æƒ…ç»ªæ¢æµ‹ï¼šæ‰©å……è‡³ 7 å¤©ï¼Œè¦†ç›–å‘¨æœ«å’Œæ·±åº¦è®¨è®º
            search_query = f"(é›ªçƒ OR è‚¡å§ OR è®¨è®º)+{query}+after:7d"
        else:
            # å®˜æ–¹æ–°é—»ï¼šç›¯é˜²ä¸»æµè´¢ç»åª’ä½“ 7 å¤©å†…åŠ¨æ€
            search_query = f"(è´¢è”ç¤¾ OR è¯åˆ¸æ—¶æŠ¥ OR ç•Œé¢æ–°é—» OR ç¬¬ä¸€è´¢ç»)+{query}+after:7d"
            
        url = f"https://news.google.com/rss/search?q={search_query}&hl=zh-CN&gl=CN&ceid=CN:zh-Hans"
        res = requests.get(url, timeout=10)
        root = ElementTree.fromstring(res.content)
        records = []
        for item in root.findall('.//item')[:15]:
            title = item.find('title').text
            # è¿‡æ»¤é™ˆæ—§å¹´ä»½æ ‡é¢˜
            if any(yr in title for yr in ["2023", "2022"]): continue
            records.append({
                "title": title.split('-')[0].strip(),
                "time": item.find('pubDate').text,
                "link": item.find('link').text,
                "source": "ğŸ”¥ ç¤¾äº¤/å¼‚åŠ¨" if is_social else "ğŸ“° å®˜æ–¹ä¿¡æº"
            })
        return pd.DataFrame(records)
    except:
        return pd.DataFrame()

# =========================
# 5ï¸âƒ£ Streamlit UI äº¤äº’
# =========================

# ä¾§è¾¹æ ï¼šæ¢æµ‹æ§åˆ¶
st.sidebar.header("ğŸ” å®¡è®¡æœç´¢æ§åˆ¶å°")
manual_key = st.sidebar.text_input("æ³¨å…¥æ‰‹åŠ¨å…³é”®è¯", placeholder="å¦‚ï¼šå›ºæ€ç”µæ±  / æœºå™¨äºº")
probe_trigger = st.sidebar.button("ğŸš€ æ‰§è¡Œ 7å¤© å…¨é‡ç©¿é€", use_container_width=True)
st.sidebar.divider()

if probe_trigger and manual_key:
    # Aæ¨¡å¼ï¼šä¸»åŠ¨æœç´¢
    st.subheader(f"âš¡ 7D ä¸“é¡¹æ¢æµ‹ï¼š{manual_key}")
    c1, c2 = st.columns(2)
    with c1:
        st.write("ğŸ“– **å®˜æ–¹ä¿¡æºå‘¨æŠ¥**")
        m_news = fetch_nova_engine(manual_key, is_social=False)
        if not m_news.empty:
            for _, r in m_news.iterrows():
                st.write(f"â— {r['title']}")
                st.link_button("åŸæ–‡", r['link'], key=f"n_{r['link']}")
        else: st.info("æœ¬å‘¨æš‚æ— ç›¸å…³å®˜æ–¹æŠ¥é“")
    with c2:
        st.write("ğŸ§  **ç¤¾äº¤æƒ…ç»ªå‘¨æŠ¥**")
        s_news = fetch_nova_engine(manual_key, is_social=True)
        if not s_news.empty:
            for _, r in s_news.iterrows():
                st.write(f"â— {r['title']}")
                st.link_button("è®¨è®ºåŒº", r['link'], key=f"s_{r['link']}")
        else: st.info("æœ¬å‘¨è®¨è®ºçƒ­åº¦è¾ƒä½")
    if st.button("â¬…ï¸ é‡ç½®çœ‹æ¿"): st.rerun()

else:
    # Bæ¨¡å¼ï¼šé»˜è®¤çœ‹æ¿æ¨¡å¼
    st.subheader("ğŸ­ æ¿å—æ·±åº¦ç©¿é€ (7å¤©åŠ¨æ€)")
    selected_sector = st.selectbox("é€‰æ‹©å®¡è®¡æ¿å—", list(SECTOR_CONFIG.keys()))
    col1, col2 = st.columns([1, 2])

    with col1:
        st.write(f"ğŸ“Š **{selected_sector}** å®æ—¶è¡Œæƒ…ï¼š")
        stock_df = get_realtime_stocks(selected_sector)
        if not stock_df.empty:
            st.table(stock_df)
        else: st.info("è¡Œæƒ…åŒæ­¥ä¸­...")

    with col2:
        st.write(f"ğŸ“° **{selected_sector}** å‘¨å†…å…³è”åŠ¨æ€ï¼š")
        q_words = SECTOR_CONFIG[selected_sector]["keywords"]
        sector_news = fetch_nova_engine(q_words, is_social=False)
        if not sector_news.empty:
            for _, row in sector_news.iterrows():
                nc1, nc2 = st.columns([4, 1])
                with nc1:
                    st.write(f"â— {row['title']}")
                    st.caption(f"_{row['time']}_")
                with nc2:
                    st.link_button("ğŸš€ ç©¿é€", row['link'], use_container_width=True)
        else: st.warning("æœ¬å‘¨æš‚æ— æ·±åº¦å…³è”åŠ¨æ€ã€‚")

    st.divider()
    # ç¤¾äº¤æƒ…ç»ªæ¨¡å—
    st.subheader(f"ğŸ§  {selected_sector} ç¤¾äº¤çƒ­åº¦/å¼‚åŠ¨ä¼ é—» (7D)")
    sentiment_df = fetch_nova_engine(selected_sector, is_social=True)
    if not sentiment_df.empty:
        scs = st.columns(2)
        for i, (_, row) in enumerate(sentiment_df.iterrows()):
            with scs[i % 2]:
                st.info(f"{row['title']}")
                st.link_button("ç©¿é€é›ªçƒ/è‚¡å§", row['link'], use_container_width=True)
    else: st.write("æœ¬å‘¨æ¿å—ç¤¾äº¤è®¨è®ºå¹³ç¨³ã€‚")

st.divider()

# 2. å…¨é‡æµï¼ˆå¸¸é©»åº•éƒ¨ï¼‰
st.subheader("ğŸ”¥ å®æ—¶å‘¨å†…å…¨é‡æ¢æµ‹ (7D)")
main_news = fetch_nova_engine("(å¹¶è´­ OR é‡ç»„ OR å€Ÿå£³ OR å›è´­ OR å¼‚åŠ¨)", is_social=False)
if not main_news.empty:
    for _, row in main_news.head(15).iterrows():
        mc1, mc2 = st.columns([5, 1])
        with mc1:
            st.write(f"ğŸ“Œ {row['title']} (_{row['time']}_)")
        with mc2:
            st.link_button("åŸæ–‡", row['link'])

st.markdown("---")
st.caption("Nova å®¡è®¡è„šæ³¨ï¼šé‡‡ç”¨ after:7d ç©¿é€æ·±åº¦ï¼Œå…³é”®è¯å·²å‡çº§ä¸º OR é€»è¾‘çŸ©é˜µã€‚")
