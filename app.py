import streamlit as st
import pandas as pd
import requests
from datetime import datetime, timedelta
from xml.etree import ElementTree
from email.utils import parsedate_to_datetime
import urllib.parse

# -----------------------------
# 1ï¸âƒ£ é¡µé¢é…ç½®
# -----------------------------
st.set_page_config(page_title="Nova æŠ•è¡Œçº§ç©¿é€çœ‹æ¿", page_icon="ğŸ›¡ï¸", layout="wide")
st.title("ğŸ›¡ï¸ æŠ•è¡Œçº§æ–°é—»æ¿å—ç©¿é€ç³»ç»Ÿ")
st.caption(f"ç³»ç»Ÿæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | æ¨¡å¼: è‡ªåŠ¨ç©¿é€æ¿å—å…³é”®è¯ï¼ˆä¸­è‹±æ–‡ Google Newsï¼‰")

# -----------------------------
# 2ï¸âƒ£ æ ¸å¿ƒæ•°æ®å­—å…¸
# -----------------------------
SECTOR_CONFIG = {
    "åŒ»è¯": {"keywords": ["åŒ»è¯", "ç”Ÿç‰©", "åˆ›æ–°è¯", "é›†é‡‡", "pharma", "biotech", "drug"], "stocks": ["600276", "300760", "603259"]},
    "æ–°èƒ½æº": {"keywords": ["é”‚ç”µ", "å®å¾·æ—¶ä»£", "å‚¨èƒ½", "å…‰ä¼", "lithium", "battery", "solar"], "stocks": ["300750", "002594", "300274"]},
    "ç§‘æŠ€": {"keywords": ["åŠå¯¼ä½“", "èŠ¯ç‰‡", "åä¸º", "AI", "semiconductor", "chip", "Huawei", "artificial intelligence"], "stocks": ["603501", "688981", "002415"]},
    "ä½ç©ºç»æµ": {"keywords": ["æ— äººæœº", "é£è¡Œæ±½è½¦", "eVTOL", "drone", "flying car"], "stocks": ["002085", "000099", "600677"]},
    "åŒ–å·¥": {"keywords": ["åŒ–å·¥", "æ¶¨ä»·", "ææ–™", "äº§èƒ½", "chemical", "materials"], "stocks": ["600309", "002493", "600096"]},
    "ç»¼åˆ/é‡ç»„": {"keywords": ["å¹¶è´­", "é‡ç»„", "è‚¡æƒè½¬è®©", "merger", "acquisition", "restructuring"], "stocks": ["600104", "000157", "600606"]},
    "åœ°äº§": {"keywords": ["æˆ¿åœ°äº§", "æ”¶å‚¨", "å­˜é‡æˆ¿", "æˆ¿è´·", "real estate", "housing"], "stocks": ["600048", "000002", "601155"]}
}

# -----------------------------
# 3ï¸âƒ£ ä¸é™æµä¸ªè‚¡è¡Œæƒ…ï¼ˆæ–°æµªï¼‰
# -----------------------------
@st.cache_data(ttl=60)
def get_realtime_stocks_sina(sector_name):
    stock_ids = SECTOR_CONFIG.get(sector_name, {}).get("stocks", [])
    if not stock_ids:
        return pd.DataFrame()
    formatted_ids = ",".join([f"sh{s}" if s.startswith('6') else f"sz{s}" for s in stock_ids])
    url = f"http://hq.sinajs.cn/list={formatted_ids}"
    try:
        headers = {"Referer": "http://finance.sina.com.cn", "User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers, timeout=5).text
        data = []
        for line in res.splitlines():
            if '"' in line:
                p = line.split('"')[1].split(',')
                if len(p) > 4:
                    name = p[0]
                    price = float(p[3])
                    prev_close = float(p[2])
                    change = (price - prev_close) / prev_close * 100 if prev_close != 0 else 0
                    data.append({"åç§°": name, "æœ€æ–°ä»·": f"{price:.2f}", "æ¶¨è·Œå¹…": f"{change:+.2f}%"})
        return pd.DataFrame(data)
    except:
        return pd.DataFrame()

# -----------------------------
# 4ï¸âƒ£ Google News RSS æŠ“å–ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰
# -----------------------------
@st.cache_data(ttl=300)
def fetch_news_google(keywords, days=7):
    records = []
    for kw in keywords:
        query = urllib.parse.quote(kw)
        rss_url = f"https://news.google.com/rss/search?q={query}&hl=zh-CN&gl=CN&ceid=CN:zh-Hans"
        try:
            res = requests.get(rss_url, timeout=10)
            root = ElementTree.fromstring(res.content)
            for item in root.findall('.//item'):
                title = item.find('title').text
                link = item.find('link').text
                pub_date = item.find('pubDate')
                if pub_date is not None:
                    try:
                        pub_dt = parsedate_to_datetime(pub_date.text)
                    except:
                        pub_dt = datetime.utcnow()
                else:
                    pub_dt = datetime.utcnow()
                if datetime.utcnow() - pub_dt <= timedelta(days=days):
                    records.append({"title": title, "time": pub_dt, "link": link})
        except:
            continue
    df = pd.DataFrame(records)
    if not df.empty:
        df.drop_duplicates(subset=['title'], inplace=True)
        df.sort_values(by='time', ascending=False, inplace=True)
    return df

# =========================
# 5ï¸âƒ£ Streamlit UI
# =========================
st.sidebar.header("ğŸ” å®¡è®¡æœç´¢æ§åˆ¶å°")
manual_key = st.sidebar.text_input("æ³¨å…¥æ‰‹åŠ¨å…³é”®è¯", placeholder="å¦‚ï¼šå¸‚å€¼ç®¡ç† / solid state battery")
probe_trigger = st.sidebar.button("ğŸš€ æ‰§è¡Œç©¿é€æ¢æµ‹", use_container_width=True)
st.sidebar.divider()

# Aæ¨¡å¼ï¼šæ‰‹åŠ¨å…³é”®è¯ç©¿é€
if probe_trigger and manual_key:
    st.subheader(f"ğŸš€ ä¸“é¡¹æœç´¢ï¼š{manual_key}")
    with st.spinner(f"æ­£åœ¨æŠ“å– '{manual_key}' ç›¸å…³çº¿ç´¢..."):
        manual_news = fetch_news_google([manual_key])
    if not manual_news.empty:
        for _, row in manual_news.iterrows():
            c1, c2 = st.columns([5, 1])
            with c1:
                st.markdown(f"**{row['title']}**")
                st.caption(f"â³ {row['time'].strftime('%Y-%m-%d %H:%M')}")
            with c2:
                st.link_button("ç©¿é€å…¨æ–‡", row['link'], use_container_width=True)
        if st.button("â¬…ï¸ é‡ç½®çœ‹æ¿è§†å›¾"):
            st.rerun()
    else:
        st.warning(f"æœªå‘ç°ä¸ '{manual_key}' ç›¸å…³çš„æœ€æ–°çº¿ç´¢ã€‚")

# Bæ¨¡å¼ï¼šæ¿å—è‡ªåŠ¨ç©¿é€
st.subheader("ğŸ­ æ¿å—æ·±åº¦ç©¿é€")
selected_sector = st.selectbox("é€‰æ‹©å®¡è®¡æ¿å—", list(SECTOR_CONFIG.keys()))
col1, col2 = st.columns([1, 2])

with col1:
    st.write(f"ğŸ“Š **{selected_sector}** å®æ—¶è¡Œæƒ…ï¼š")
    stock_df = get_realtime_stocks_sina(selected_sector)
    if not stock_df.empty:
        st.table(stock_df)
    else:
        st.info("è¡Œæƒ…æ¥å£åŒæ­¥ä¸­...")

with col2:
    st.write(f"ğŸ“° **{selected_sector}** æ¿å—å…³è”åŠ¨æ€ï¼š")
    sector_news = fetch_news_google(SECTOR_CONFIG[selected_sector]["keywords"])
    if not sector_news.empty:
        for _, row in sector_news.iterrows():
            nc1, nc2 = st.columns([4, 1])
            with nc1:
                st.write(f"â— {row['title']}")
                st.caption(f"_{row['time'].strftime('%Y-%m-%d %H:%M')}_")
            with nc2:
                st.link_button("ğŸš€ ç©¿é€", row['link'], use_container_width=True)
    else:
        st.warning(f"ğŸ’¡ æš‚æœªå‘ç°ä¸ {selected_sector} ç›¸å…³çš„æœ€æ–°çº¿ç´¢ã€‚")

st.divider()

# å…¨é‡æµ
st.subheader("ğŸ”¥ å®æ—¶æ—©ç›˜å…¨é‡æµ")
all_news = fetch_news_google([kw for sector in SECTOR_CONFIG.values() for kw in sector["keywords"]])
if not all_news.empty:
    for _, row in all_news.head(10).iterrows():
        mc1, mc2 = st.columns([5, 1])
        with mc1:
            st.write(f"ğŸ“Œ {row['title']} (_{row['time'].strftime('%Y-%m-%d %H:%M')}_)")
        with mc2:
            st.link_button("åŸæ–‡", row['link'])
else:
    st.error("æ•°æ®æµå—é˜»æˆ–è¿‘æœŸæ— æ–°æ–°é—»ã€‚")

st.markdown("---")
st.caption("Nova å®¡è®¡è„šæ³¨ï¼šæ–°é—»è‡ªåŠ¨æå–æ¿å—å…³é”®è¯ï¼ˆä¸­è‹±æ–‡ Google Newsï¼‰ï¼Œæœ€è¿‘7å¤©å†…ï¼Œå·²å»é‡å¹¶æŒ‰æ—¶é—´æ’åºã€‚")
