import streamlit as st
import pandas as pd
import requests
from datetime import datetime, timedelta
from xml.etree import ElementTree

# -----------------------------
# 1ï¸âƒ£ é¡µé¢é…ç½®
# -----------------------------
st.set_page_config(page_title="Nova æŠ•è¡Œçº§ç©¿é€çœ‹æ¿", page_icon="ğŸ›¡ï¸", layout="wide")
st.title("ğŸ›¡ï¸ æŠ•è¡Œçº§æ–°é—»æ¿å—ç©¿é€ç³»ç»Ÿ")
st.caption(f"ç³»ç»Ÿæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | æ¨¡å¼: å®˜æ–¹ RSS + æ‰‹åŠ¨å…³é”®è¯ç©¿é€")

# -----------------------------
# 2ï¸âƒ£ æ ¸å¿ƒæ•°æ®å­—å…¸
# -----------------------------
SECTOR_CONFIG = {
    "åŒ»è¯": {"keywords": "åŒ»è¯+ç”Ÿç‰©+åˆ›æ–°è¯+é›†é‡‡", "stocks": ["600276", "300760", "603259"]},
    "æ–°èƒ½æº": {"keywords": "é”‚ç”µ+å®å¾·æ—¶ä»£+å‚¨èƒ½+å…‰ä¼", "stocks": ["300750", "002594", "300274"]},
    "ç§‘æŠ€": {"keywords": "åŠå¯¼ä½“+èŠ¯ç‰‡+åä¸º+AI", "stocks": ["603501", "688981", "002415"]},
    "ä½ç©ºç»æµ": {"keywords": "æ— äººæœº+é£è¡Œæ±½è½¦+eVTOL", "stocks": ["002085", "000099", "600677"]},
    "åŒ–å·¥": {"keywords": "åŒ–å·¥+æ¶¨ä»·+ææ–™+äº§èƒ½", "stocks": ["600309", "002493", "600096"]},
    "ç»¼åˆ/é‡ç»„": {"keywords": "å¹¶è´­+é‡ç»„+è‚¡æƒè½¬è®©", "stocks": ["600104", "000157", "600606"]},
    "åœ°äº§": {"keywords": "æˆ¿åœ°äº§+æ”¶å‚¨+å­˜é‡æˆ¿+æˆ¿è´·", "stocks": ["600048", "000002", "601155"]}
}

# -----------------------------
# 3ï¸âƒ£ ä¸é™æµä¸ªè‚¡è¡Œæƒ…æ¥å£
# -----------------------------
@st.cache_data(ttl=60)
def get_realtime_stocks(sector_name):
    stock_ids = SECTOR_CONFIG.get(sector_name, {}).get("stocks", ["600519"])
    formatted_ids = ",".join([f"sh{s}" if s.startswith('6') else f"sz{s}" for s in stock_ids])
    url = f"http://hq.sinajs.cn/list={formatted_ids}"
    try:
        headers = {"Referer": "http://finance.sina.com.cn", "User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers, timeout=5).text
        data = []
        for line in res.splitlines():
            if '"' in line:
                p = line.split('"')[1].split(',')
                if len(p) > 4:
                    name, price, prev_close = p[0], float(p[3]), float(p[2])
                    change = (price - prev_close) / prev_close * 100
                    data.append({"åç§°": name, "æœ€æ–°ä»·": f"{price:.2f}", "æ¶¨è·Œå¹…": f"{change:+.2f}%"})
        return pd.DataFrame(data)
    except:
        return pd.DataFrame()

# -----------------------------
# 4ï¸âƒ£ å®˜æ–¹ RSS æ–°é—»æŠ“å–ï¼ˆæ”¯æŒä¸€å‘¨å†…ï¼‰
# -----------------------------
OFFICIAL_RSS = [
    # äº¤æ˜“æ‰€å…¬å‘Š
    "http://www.sse.com.cn/rss/announcement/",
    "http://www.szse.cn/rss/news/",
    # è¯ç›‘ä¼šæ–°é—»
    "http://www.csrc.gov.cn/pub/newsite/rss/news.xml",
    # æ–°åç¤¾è´¢ç»
    "http://www.xinhuanet.com/finance/rss.xml"
]

@st.cache_data(ttl=300)
def fetch_official_news(query="", days=7):
    records = []
    cutoff = datetime.utcnow() - timedelta(days=days)
    for rss_url in OFFICIAL_RSS:
        try:
            res = requests.get(rss_url, timeout=10)
            root = ElementTree.fromstring(res.content)
            for item in root.findall('.//item')[:50]:  # å–æœ€æ–°50æ¡
                title = item.find('title').text or ""
                link = item.find('link').text or ""
                pub_date = item.find('pubDate').text or ""
                try:
                    pub_dt = datetime.strptime(pub_date, "%a, %d %b %Y %H:%M:%S %Z")
                except:
                    pub_dt = datetime.utcnow()
                # ä»…ä¿ç•™æŒ‡å®šå¤©æ•°å†…
                if pub_dt < cutoff:
                    continue
                # å…³é”®è¯è¿‡æ»¤
                if query.lower() in title.lower():
                    records.append({"title": title, "time": pub_date, "link": link})
        except Exception as e:
            print(f"æŠ“å– {rss_url} å¤±è´¥:", e)
    return pd.DataFrame(records)

# =========================
# 5ï¸âƒ£ Streamlit UI äº¤äº’
# =========================
st.sidebar.header("ğŸ” å®¡è®¡æœç´¢æ§åˆ¶å°")
manual_key = st.sidebar.text_input("æ³¨å…¥æ‰‹åŠ¨å…³é”®è¯", placeholder="å¦‚ï¼šå¸‚å€¼ç®¡ç† / å›ºæ€ç”µæ± ")
probe_trigger = st.sidebar.button("ğŸš€ æ‰§è¡Œç©¿é€æ¢æµ‹", use_container_width=True)
st.sidebar.divider()

# ä¸»å±é€»è¾‘
if probe_trigger and manual_key:
    st.subheader(f"ğŸš€ ä¸“é¡¹æœç´¢ï¼š{manual_key}")
    with st.spinner(f"æŠ“å– '{manual_key}' ç›¸å…³å®˜æ–¹çº¿ç´¢..."):
        news_df = fetch_official_news(manual_key)
    if not news_df.empty:
        for _, row in news_df.iterrows():
            c1, c2 = st.columns([5, 1])
            with c1:
                st.markdown(f"**{row['title']}**")
                st.caption(f"â³ {row['time']}")
            with c2:
                st.link_button("ç©¿é€å…¨æ–‡", row['link'], use_container_width=True)
            st.divider()
    else:
        st.warning(f"æœªå‘ç°ä¸ '{manual_key}' ç›¸å…³çš„å®˜æ–¹çº¿ç´¢ã€‚")
else:
    # æ¿å—é»˜è®¤çœ‹æ¿
    st.subheader("ğŸ­ æ¿å—æ·±åº¦ç©¿é€")
    selected_sector = st.selectbox("é€‰æ‹©å®¡è®¡æ¿å—", list(SECTOR_CONFIG.keys()))
    col1, col2 = st.columns([1, 2])

    with col1:
        st.write(f"ğŸ“Š **{selected_sector}** å®æ—¶è¡Œæƒ…ï¼š")
        stock_df = get_realtime_stocks(selected_sector)
        if not stock_df.empty:
            st.table(stock_df)
        else:
            st.info("è¡Œæƒ…æ¥å£åŒæ­¥ä¸­...")

    with col2:
        st.write(f"ğŸ“° **{selected_sector}** å®˜æ–¹æ–°é—»/å…¬å‘Šï¼ˆ7å¤©ï¼‰:")
        q_words = SECTOR_CONFIG[selected_sector]["keywords"]
        sector_news = fetch_official_news(q_words, days=7)
        if not sector_news.empty:
            for _, row in sector_news.iterrows():
                nc1, nc2 = st.columns([4, 1])
                with nc1:
                    st.write(f"â— {row['title']}")
                    st.caption(f"_{row['time']}_")
                with nc2:
                    st.link_button("ğŸš€ ç©¿é€", row['link'], use_container_width=True)
        else:
            st.warning(f"ğŸ’¡ æš‚æœªå‘ç°ä¸ {selected_sector} ç›¸å…³çš„ä¸€å‘¨å®˜æ–¹çº¿ç´¢ã€‚")

st.divider()
st.markdown("---")
st.caption("Nova å®¡è®¡è„šæ³¨ï¼šä½¿ç”¨å®˜æ–¹ RSS æ¥æºï¼ˆäº¤æ˜“æ‰€å…¬å‘Š + è¯ç›‘ä¼š + æ–°åç¤¾è´¢ç»ï¼‰ï¼Œæ”¯æŒ 7 å¤©æ–°é—»ç©¿é€ã€‚")
