import streamlit as st
import pandas as pd
import requests
from datetime import datetime
from collections import Counter

# -----------------------------
# 1ï¸âƒ£ é¡µé¢é…ç½®
# -----------------------------
st.set_page_config(page_title="Nova æŠ•è¡Œçº§ç©¿é€çœ‹æ¿", page_icon="ğŸ›¡ï¸", layout="wide")
st.title("ğŸ›¡ï¸ æŠ•è¡Œçº§æ–°é—»æ¿å—ç©¿é€ç³»ç»Ÿ")
st.caption(f"ç³»ç»Ÿæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | æ¨¡å¼: ä¸œè´¢ API å®æ—¶ç©¿é€")

# -----------------------------
# 2ï¸âƒ£ æ ¸å¿ƒæ•°æ®å­—å…¸
# -----------------------------
SECTOR_CONFIG = {
    "åŒ»è¯": {"keywords": "åŒ»è¯, åˆ›æ–°è¯, 300760, 600276", "stocks": ["600276", "300760", "603259"]},
    "æ–°èƒ½æº": {"keywords": "é”‚ç”µ, å®å¾·æ—¶ä»£, å‚¨èƒ½, 300750", "stocks": ["300750", "002594", "300274"]},
    "ç§‘æŠ€": {"keywords": "èŠ¯ç‰‡, åŠå¯¼ä½“, åä¸º, AI, 688981", "stocks": ["603501", "688981", "002415"]},
    "ä½ç©ºç»æµ": {"keywords": "æ— äººæœº, é£è¡Œæ±½è½¦, eVTOL, 002085", "stocks": ["002085", "000099", "600677"]},
    "åŒ–å·¥": {"keywords": "åŒ–å·¥æ¶¨ä»·, ç£·åŒ–å·¥, 600309", "stocks": ["600309", "002493", "600096"]},
    "ç»¼åˆ/é‡ç»„": {"keywords": "å¹¶è´­é‡ç»„, è‚¡æƒè½¬è®©, å¸‚å€¼ç®¡ç†", "stocks": ["600104", "000157", "600606"]},
    "åœ°äº§": {"keywords": "æˆ¿åœ°äº§, æˆ¿è´·åˆ©ç‡, ä¸‡ç§‘, 000002", "stocks": ["600048", "000002", "601155"]}
}

# -----------------------------
# 3ï¸âƒ£ è¡Œæƒ…å¼•æ“
# -----------------------------
@st.cache_data(ttl=60)
def get_realtime_stocks(sector_name):
    stock_ids = SECTOR_CONFIG.get(sector_name, {}).get("stocks", ["600519"])
    formatted_ids = ",".join([f"sh{s}" if s.startswith('6') else f"sz{s}" for s in stock_ids])
    url = f"http://hq.sinajs.cn/list={formatted_ids}"
    try:
        headers = {"Referer": "http://finance.sina.com.cn", "User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers, timeout=5).text
        data = []
        for line in res.splitlines():
            if '"' in line:
                p = line.split('"')[1].split(',')
                if len(p) > 4:
                    name, price, prev_close = p[0], float(p[3]), float(p[2])
                    change = (price - prev_close) / prev_close * 100
                    data.append({"åç§°": name, "æœ€æ–°ä»·": f"{price:.2f}", "æ¶¨è·Œå¹…": f"{change:+.2f}%"})
        return pd.DataFrame(data)
    except:
        return pd.DataFrame()

# -----------------------------
# 4ï¸âƒ£ æ ¸å¿ƒæ¢æµ‹å¼•æ“ (API æ‹†è§£å¢å¼ºç‰ˆ)
# -----------------------------
@st.cache_data(ttl=120)
def fetch_nova_engine(query="", is_social=False):
    records = []
    try:
        # å°† "A OR B" æˆ– "A,B" ç»Ÿä¸€æ‹†åˆ†ä¸ºåˆ—è¡¨
        keywords = [k.strip() for k in query.replace("OR", ",").split(",") if k.strip()]
        
        for kw in keywords:
            if is_social:
                # ç¤¾äº¤æ¥å£
                url = f"http://push2.eastmoney.com/api/qt/clist/get?pn=1&pz=8&po=1&np=1&ut=7eea3edcaed734bea9cbfc24409ed989&fid=f3&fs=b:MK0001&fields=f12,f14,f2,f13&q={kw}"
            else:
                # æ–°é—»æ¥å£
                url = f"http://push2.eastmoney.com/api/qt/kcstock/get?pn=1&pz=8&po=1&np=1&ut=7eea3edcaed734bea9cbfc24409ed989&fid=f12&fields=f12,f14,f2,f13&q={kw}"
            
            headers = {"User-Agent": "Mozilla/5.0"}
            response = requests.get(url, headers=headers, timeout=5).json()
            items = response.get("data", {}).get("diff", [])

            for item in items:
                title = item.get("f14", item.get("f12", "æ— æ ‡é¢˜"))
                # é“¾æ¥æ¸…æ´—ï¼šä¸œè´¢ API æœ‰æ—¶è¿”å›çº¯ IDï¼Œéœ€æ‹¼æ¥
                raw_link = item.get("f13", "")
                link = raw_link if "http" in raw_link else f"https://finance.eastmoney.com/a/{raw_link}.html"
                
                records.append({
                    "title": title,
                    "time": datetime.fromtimestamp(item.get("f2", 0)).strftime('%m-%d %H:%M') if item.get("f2") else "åˆšåˆš",
                    "link": link,
                    "source": "ğŸ”¥ ç¤¾äº¤/å¼‚åŠ¨" if is_social else "ğŸ“° å®˜æ–¹ä¿¡æº"
                })
        
        df = pd.DataFrame(records)
        if not df.empty:
            return df.drop_duplicates(subset=['title']) # å»é™¤ä¸åŒå…³é”®è¯å‘½ä¸­çš„é‡å¤æ–°é—»
        return df
    except Exception as e:
        return pd.DataFrame(records)

# =========================
# 5ï¸âƒ£ Streamlit UI äº¤äº’
# =========================

st.sidebar.header("ğŸ” å®¡è®¡æ§åˆ¶å°")
manual_key = st.sidebar.text_input("æ‰‹åŠ¨ç©¿é€ (ä»£ç /çƒ­è¯)", placeholder="å¦‚: 300760")
probe_trigger = st.sidebar.button("ğŸš€ æ‰§è¡Œæ·±åº¦æ¢æµ‹", use_container_width=True)

if probe_trigger and manual_key:
    st.subheader(f"âš¡ ä¸“é¡¹æ¢æµ‹ï¼š{manual_key}")
    c1, c2 = st.columns(2)
    with c1:
        st.write("ğŸ“– **å®˜æ–¹ä¿¡æº**")
        res_n = fetch_nova_engine(manual_key, is_social=False)
        if not res_n.empty:
            for _, r in res_n.iterrows():
                st.write(f"â— {r['title']}")
                st.link_button("ç©¿é€åŸæ–‡", r['link'], key=f"n_{r['link']}")
        else: st.info("æ— ç›¸å…³åŠ¨æ€")
    with c2:
        st.write("ğŸ§  **ç¤¾åŒºæƒ…ç»ª**")
        res_s = fetch_nova_engine(manual_key, is_social=True)
        if not res_s.empty:
            for _, r in res_s.iterrows():
                st.write(f"â— {r['title']}")
                st.link_button("è¿›å…¥ç°åœº", r['link'], key=f"s_{r['link']}")
        else: st.info("è®¨è®ºå¹³ç¨³")
    if st.button("â¬…ï¸ é‡ç½®"): st.rerun()

else:
    st.subheader("ğŸ­ æ¿å—æ·±åº¦ç©¿é€")
    selected_sector = st.selectbox("å®¡è®¡æ¿å—", list(SECTOR_CONFIG.keys()))
    col1, col2 = st.columns([1, 2])

    with col1:
        st.write("ğŸ“Š **å®æ—¶è¡Œæƒ…**")
        st.table(get_realtime_stocks(selected_sector))

    with col2:
        st.write(f"ğŸ“° **{selected_sector}** æ ¸å¿ƒåŠ¨æ€")
        q = SECTOR_CONFIG[selected_sector]["keywords"]
        df_sector = fetch_nova_engine(q, is_social=False)
        if not df_sector.empty:
            for _, row in df_sector.iterrows():
                st.write(f"â— {row['title']} (_{row['time']}_)")
                st.link_button("é˜…è¯»åŸæ–‡", row['link'], key=f"sec_{row['link']}")
        else:
            st.warning("ğŸ’¡ API æš‚æœªåŒ¹é…ã€‚è¯·å°è¯•åœ¨ä¾§è¾¹æ æ‰‹åŠ¨è¾“å…¥ä¸ªè‚¡ä»£ç ç©¿é€ã€‚")

st.markdown("---")
st.caption("Nova å®¡è®¡è„šæ³¨ï¼šé‡‡ç”¨ API å…³é”®è¯ token åŒ–æŠ€æœ¯ï¼Œå·²è‡ªåŠ¨æ¸…æ´—é“¾æ¥ã€‚")
