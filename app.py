import streamlit as st
import pandas as pd
import requests
from collections import Counter
from datetime import datetime, timedelta
from xml.etree import ElementTree

# -----------------------------
# 1ï¸âƒ£ é¡µé¢é…ç½®
# -----------------------------
st.set_page_config(page_title="Nova æŠ•è¡Œçº§ç©¿é€çœ‹æ¿", page_icon="ğŸ›¡ï¸", layout="wide")
st.title("ğŸ›¡ï¸ æŠ•è¡Œçº§æ–°é—»æ¿å—ç©¿é€ç³»ç»Ÿ")
st.caption(f"ç³»ç»Ÿæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | æ¨¡å¼: 24Hæé€Ÿç©¿é€ + ç¤¾äº¤æƒ…ç»ªç›‘æ§")

# -----------------------------
# 2ï¸âƒ£ æ ¸å¿ƒæ•°æ®å­—å…¸
# -----------------------------
SECTOR_CONFIG = {
    "åŒ»è¯": {"keywords": "åŒ»è¯+ç”Ÿç‰©+åˆ›æ–°è¯+é›†é‡‡", "stocks": ["600276", "300760", "603259"]},
    "æ–°èƒ½æº": {"keywords": "é”‚ç”µ+å®å¾·æ—¶ä»£+å‚¨èƒ½+å…‰ä¼", "stocks": ["300750", "002594", "300274"]},
    "ç§‘æŠ€": {"keywords": "åŠå¯¼ä½“+èŠ¯ç‰‡+åä¸º+AI", "stocks": ["603501", "688981", "002415"]},
    "ä½ç©ºç»æµ": {"keywords": "æ— äººæœº+é£è¡Œæ±½è½¦+eVTOL", "stocks": ["002085", "000099", "600677"]},
    "åŒ–å·¥": {"keywords": "åŒ–å·¥+æ¶¨ä»·+ææ–™+äº§èƒ½", "stocks": ["600309", "002493", "600096"]},
    "ç»¼åˆ/é‡ç»„": {"keywords": "å¹¶è´­+é‡ç»„+é‡ç»„+è‚¡æƒè½¬è®©", "stocks": ["600104", "000157", "600606"]},
    "åœ°äº§": {"keywords": "æˆ¿åœ°äº§+æ”¶å‚¨+å­˜é‡æˆ¿+æˆ¿è´·", "stocks": ["600048", "000002", "601155"]}
}

# -----------------------------
# 3ï¸âƒ£ è¡Œæƒ…å¼•æ“ (æ–°æµªHTMLé€šé“)
# -----------------------------
@st.cache_data(ttl=60)
def get_realtime_stocks(sector_name):
    stock_ids = SECTOR_CONFIG.get(sector_name, {}).get("stocks", ["600519"])
    formatted_ids = ",".join([f"sh{s}" if s.startswith('6') else f"sz{s}" for s in stock_ids])
    url = f"http://hq.sinajs.cn/list={formatted_ids}"
    try:
        headers = {"Referer": "http://finance.sina.com.cn", "User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers, timeout=5).text
        data = []
        for line in res.splitlines():
            if '"' in line:
                p = line.split('"')[1].split(',')
                if len(p) > 4:
                    name, price, prev_close = p[0], float(p[3]), float(p[2])
                    change = (price - prev_close) / prev_close * 100
                    data.append({"åç§°": name, "æœ€æ–°ä»·": f"{price:.2f}", "æ¶¨è·Œå¹…": f"{change:+.2f}%"})
        return pd.DataFrame(data)
    except:
        return pd.DataFrame()

# -----------------------------
# 4ï¸âƒ£ æ ¸å¿ƒæ¢æµ‹å¼•æ“ (æ–°é—»+æƒ…ç»ª)
# -----------------------------
@st.cache_data(ttl=120)
def fetch_nova_engine(query="", is_social=False):
    """
    Nova å¼•æ“ï¼šæ”¯æŒ 24H å¼ºåˆ¶æ–°é—»æ¢æµ‹æˆ–ç¤¾äº¤æƒ…ç»ªæ¢æµ‹
    """
    try:
        if is_social:
            # æƒ…ç»ªæ¢æµ‹ï¼šä¸“é—¨ç›¯é˜²é›ªçƒä¸è‚¡å§å¼‚åŠ¨
            search_query = f"(é›ªçƒ OR è‚¡å§ OR å¼‚åŠ¨)+{query}+after:1d"
        else:
            # å®˜æ–¹æ–°é—»ï¼šç›¯é˜²ä¸»æµè´¢ç»åª’ä½“ 24H å†…åŠ¨æ€
            search_query = f"(è´¢è”ç¤¾ OR è¯åˆ¸æ—¶æŠ¥ OR ç•Œé¢æ–°é—»)+{query}+after:1d"
            
        url = f"https://news.google.com/rss/search?q={search_query}&hl=zh-CN&gl=CN&ceid=CN:zh-Hans"
        res = requests.get(url, timeout=10)
        root = ElementTree.fromstring(res.content)
        records = []
        for item in root.findall('.//item')[:12]:
            title = item.find('title').text
            # è¿‡æ»¤æ—§é—»
            if any(yr in title for yr in ["2024", "2025"]): continue
            records.append({
                "title": title.split('-')[0].strip(),
                "time": item.find('pubDate').text,
                "link": item.find('link').text,
                "source": "ğŸ”¥ ç¤¾äº¤/å¼‚åŠ¨" if is_social else "ğŸ“° å®˜æ–¹ä¿¡æº"
            })
        return pd.DataFrame(records)
    except:
        return pd.DataFrame()

# =========================
# 5ï¸âƒ£ Streamlit UI äº¤äº’
# =========================

# ä¾§è¾¹æ ï¼šæ¢æµ‹æ§åˆ¶
st.sidebar.header("ğŸ” å®¡è®¡æœç´¢æ§åˆ¶å°")
manual_key = st.sidebar.text_input("æ³¨å…¥æ‰‹åŠ¨å…³é”®è¯", placeholder="å¦‚ï¼šå¸‚å€¼ç®¡ç† / å›ºæ€ç”µæ± ")
probe_trigger = st.sidebar.button("ğŸš€ æ‰§è¡Œ 24H å…¨å±€æ¢æµ‹", use_container_width=True)
st.sidebar.divider()

if probe_trigger and manual_key:
    # Aæ¨¡å¼ï¼šä¸»åŠ¨æœç´¢
    st.subheader(f"âš¡ 24H ä¸“é¡¹æ¢æµ‹ï¼š{manual_key}")
    c1, c2 = st.columns(2)
    with c1:
        st.write("ğŸ“– **å®˜æ–¹ä¿¡æºæœ€æ–°**")
        m_news = fetch_nova_engine(manual_key, is_social=False)
        if not m_news.empty:
            for _, r in m_news.iterrows():
                st.write(f"â— {r['title']}")
                st.link_button("åŸæ–‡", r['link'], key=f"n_{r['link']}")
        else: st.info("æš‚æ— å®˜æ–¹æŠ¥é“")
    with c2:
        st.write("ğŸ§  **ç¤¾äº¤æƒ…ç»ªå¼‚åŠ¨**")
        s_news = fetch_nova_engine(manual_key, is_social=True)
        if not s_news.empty:
            for _, r in s_news.iterrows():
                st.write(f"â— {r['title']}")
                st.link_button("ç©¿é€è®¨è®ºåŒº", r['link'], key=f"s_{r['link']}")
        else: st.info("æš‚æ— çƒ­çƒˆè®¨è®º")
    if st.button("â¬…ï¸ é‡ç½®çœ‹æ¿"): st.rerun()

else:
    # Bæ¨¡å¼ï¼šé»˜è®¤çœ‹æ¿æ¨¡å¼
    st.subheader("ğŸ­ æ¿å—æ·±åº¦ç©¿é€")
    selected_sector = st.selectbox("é€‰æ‹©å®¡è®¡æ¿å—", list(SECTOR_CONFIG.keys()))
    col1, col2 = st.columns([1, 2])

    with col1:
        st.write(f"ğŸ“Š **{selected_sector}** å®æ—¶è¡Œæƒ…ï¼š")
        stock_df = get_realtime_stocks(selected_sector)
        if not stock_df.empty:
            st.table(stock_df)
        else: st.info("è¡Œæƒ…åŒæ­¥ä¸­...")

    with col2:
        st.write(f"ğŸ“° **{selected_sector}** 24H å…³è”åŠ¨æ€ï¼š")
        q_words = SECTOR_CONFIG[selected_sector]["keywords"]
        sector_news = fetch_nova_engine(q_words, is_social=False)
        if not sector_news.empty:
            for _, row in sector_news.iterrows():
                nc1, nc2 = st.columns([4, 1])
                with nc1:
                    st.write(f"â— {row['title']}")
                    st.caption(f"_{row['time']}_")
                with nc2:
                    st.link_button("ğŸš€ ç©¿é€", row['link'], use_container_width=True)
        else: st.warning("24å°æ—¶å†…æ— æ–°åŠ¨æ€ã€‚")

    st.divider()
    # ç¤¾äº¤æƒ…ç»ªæ¨¡å—
    st.subheader(f"ğŸ§  {selected_sector} ç¤¾äº¤æƒ…ç»ª/ä¼ é—»æ¢æµ‹ (24H)")
    sentiment_df = fetch_nova_engine(selected_sector, is_social=True)
    if not sentiment_df.empty:
        scs = st.columns(2)
        for i, (_, row) in enumerate(sentiment_df.iterrows()):
            with scs[i % 2]:
                st.info(f"{row['title']}")
                st.link_button("è¿›å…¥é›ªçƒ/è‚¡å§", row['link'], use_container_width=True)
    else: st.write("å½“å‰æ¿å—è®¨è®ºçƒ­åº¦å¹³ç¨³ã€‚")

st.divider()

# 2. å…¨é‡æµï¼ˆå¸¸é©»åº•éƒ¨ï¼‰
st.subheader("ğŸ”¥ å®æ—¶æ—©ç›˜å…¨é‡æµ (24H)")
main_news = fetch_nova_engine("å¹¶è´­+å›è´­+IPO+å¼‚åŠ¨", is_social=False)
if not main_news.empty:
    for _, row in main_news.head(10).iterrows():
        mc1, mc2 = st.columns([5, 1])
        with mc1:
            st.write(f"ğŸ“Œ {row['title']} (_{row['time']}_)")
        with mc2:
            st.link_button("åŸæ–‡", row['link'])

st.markdown("---")
st.caption("Nova å®¡è®¡è„šæ³¨ï¼šå¼ºåˆ¶ after:1d è¿‡æ»¤æ—§é—»ï¼ŒåŒæ­¥ç©¿é€é›ªçƒ/è‚¡å§ç¤¾äº¤æ•°æ®ã€‚")
