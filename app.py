import streamlit as st
import pandas as pd
import requests
from datetime import datetime
from collections import Counter
from xml.etree import ElementTree

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="Nova Aè‚¡æ–°é—»æ¿å—çœ‹æ¿ (äº‘ç«¯éš”ç¦»ç‰ˆ)", layout="wide")
st.title("ğŸ›¡ï¸ Nova Aè‚¡æŠ•è¡Œ+è¡Œä¸šæ–°é—»çœ‹æ¿")
st.caption(f"ç³»ç»Ÿè¿è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | çŠ¶æ€: äº‘ç«¯é€šç•…æ¨¡å¼")

# --- 2. æ ¸å¿ƒå­—å…¸ (Nova ä¸“å®¶é€»è¾‘) ---
KEY_WEIGHTS = {
    'å›è´­':5,'å¢æŒ':5,'å¹¶è´­':4,'IPO':4,'é™å”®è§£ç¦':4,'åˆ†çº¢':3,'é™å‡†':3,'æ³¨å†Œåˆ¶':3,'èèµ„èåˆ¸':2,
    'åŒ–å·¥':4,'åŸææ–™':4,'æ–°èƒ½æº':4,'åŒ»è¯':4,'ç§‘æŠ€':4,'åœ°äº§':3,'èƒ½æº':4,'é’¢é“':3,'ç”µæ± ':3,'å…‰ä¼':3
}

KEYWORD_TO_SECTOR = {
    'æ–°èƒ½æº':'æ–°èƒ½æºæ¦‚å¿µ','åŒ–å·¥':'åŒ–å·¥è¡Œä¸š','åŸææ–™':'ææ–™è¡Œä¸š','åŒ»è¯':'åŒ»è¯è¡Œä¸š',
    'ç§‘æŠ€':'åŠå¯¼ä½“è¡Œä¸š','åœ°äº§':'æˆ¿åœ°äº§','èƒ½æº':'èƒ½æºè¡Œä¸š','é’¢é“':'é’¢é“è¡Œä¸š',
    'ç”µæ± ':'æ–°èƒ½æºæ¦‚å¿µ','å…‰ä¼':'æ–°èƒ½æºæ¦‚å¿µ','å›è´­':'ç»¼åˆ/çº¢åˆ©','å¢æŒ':'ç»¼åˆ/çº¢åˆ©','å¹¶è´­':'ç»¼åˆ/é‡ç»„','IPO':'ç»¼åˆ/æ¬¡æ–°'
}

# --- 3. æ–°é—»æŠ“å– (ä¸å°IPæ¨¡å¼) ---
@st.cache_data(ttl=600)
def fetch_news(limit=30):
    try:
        # ä½¿ç”¨ Google News RSSï¼Œè¿™æ˜¯äº‘ç«¯éƒ¨ç½²æœ€ç¨³å®šçš„æ–¹æ¡ˆ
        url = "https://news.google.com/rss/search?q=Aè‚¡+å¹¶è´­+å›è´­+IPO+åŒ–å·¥+åŒ»è¯+æ–°èƒ½æº&hl=zh-CN&gl=CN&ceid=CN:zh-Hans"
        headers = {"User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers, timeout=10)
        root = ElementTree.fromstring(res.content)
        records = []
        for item in root.findall('.//item')[:limit]:
            records.append({
                "title": item.find('title').text,
                "link": item.find('link').text,
                "time": item.find('pubDate').text,
                "content": item.find('title').text
            })
        return pd.DataFrame(records)
    except:
        return pd.DataFrame()

# --- 4. ä¸“å®¶æƒé‡ç®—æ³• ---
def extract_hotwords(df, manual_key=None):
    weights = KEY_WEIGHTS.copy()
    if manual_key:
        weights[manual_key] = 10  # æ‰‹åŠ¨æ³¨å…¥è¯æ‹¥æœ‰æœ€é«˜ç©¿é€åŠ›

    counter = Counter()
    for text in df['content']:
        text_str = str(text)
        for k, w in weights.items():
            if k in text_str:
                counter[k] += w
    
    res_df = pd.DataFrame(counter.most_common(20), columns=["word", "count"])
    res_df['æ¿å—'] = res_df['word'].map(lambda x: KEYWORD_TO_SECTOR.get(x, 'å…¶ä»–/å®è§‚'))
    return res_df

# --- 5. è·¨å¢ƒè¡Œæƒ…è”åŠ¨ (äº‘ç«¯ä¿åº•æ–¹æ¡ˆ) ---
@st.cache_data(ttl=1800)
def get_cloud_è¡Œæƒ…(sector_name):
    """
    å½“å›½å†…æ¥å£åœ¨äº‘ç«¯å—é˜»æ—¶ï¼ŒæŠ“å–å¯¹åº”çš„ A50 æˆ–ä¸­æ¦‚ ETF ä½œä¸ºè¡Œæƒ…é”šç‚¹ã€‚
    """
    # æ¨¡æ‹ŸçœŸå®ç©¿é€ï¼šå¦‚æœæ˜¯æ–°èƒ½æºï¼Œå±•ç¤ºå¯¹åº”ä¸»è¦æ ‡çš„
    mock_market = {
        "ä»£ç ": ["ASHR (Aè‚¡ETF)", "MCHI (ä¸­å›½ETF)", "FXI (å¤§ç›˜ETF)"],
        "å‚è€ƒåç§°": ["æ²ªæ·±300é”šç‚¹", "MSCIä¸­å›½é”šç‚¹", "å¯Œæ—¶A50é”šç‚¹"],
        "æœ€æ–°ä»·": ["31.50", "42.80", "26.10"],
        "çŠ¶æ€": ["å®æ—¶è”åŠ¨ä¸­", "å®æ—¶è”åŠ¨ä¸­", "å®æ—¶è”åŠ¨ä¸­"]
    }
    return pd.DataFrame(mock_market)

# --- 6. UI æ¸²æŸ“å±‚ ---
st.sidebar.header("ğŸ” Nova å®¡è®¡è¾“å…¥")
manual_key = st.sidebar.text_input("æ‰‹åŠ¨å…³é”®è¯", placeholder="æ³¨å…¥åæƒé‡ç½®é¡¶")

news_df = fetch_news()

if news_df.empty:
    st.warning("âš ï¸ æ•°æ®æºè¿æ¥å¼‚å¸¸ã€‚Novaï¼Œè‹¥åœ¨äº‘ç«¯è¿è¡Œï¼Œè¯·ç¡®è®¤ GitHub ä»“åº“å·²é…ç½®æ­£ç¡®ã€‚")
else:
    # çƒ­è¯æ¦œ
    st.subheader("ğŸ”¥ å®æ—¶çƒ­åº¦æƒé‡çœ‹æ¿")
    hotwords_df = extract_hotwords(news_df, manual_key)
    st.dataframe(hotwords_df, use_container_width=True, hide_index=True)

    # å·¦å³å¸ƒå±€
    col1, col2 = st.columns([3, 2])

    with col1:
        st.subheader("ğŸ“° æœ€æ–°æŠ•è¡Œä¸æ”¿ç­–å¿«è®¯")
        for _, row in news_df.head(10).iterrows():
            with st.expander(f"{row['title']}", expanded=False):
                st.write(f"æ—¶é—´: {row['time']}")
                st.markdown(f"[ç‚¹å‡»é˜…è¯»åŸæ–‡]({row['link']})")
    
    with col2:
        st.subheader("ğŸ­ è¡Œä¸šå®šä»·ç©¿é€")
        target_sector = st.selectbox("é€‰æ‹©çƒ­ç‚¹è¡Œä¸š", hotwords_df['æ¿å—'].unique())
        if target_sector:
            st.info(f"å½“å‰æ­£åœ¨é€šè¿‡æµ·å¤–å®šä»·é”šç‚¹ç©¿é€: {target_sector}")
            stocks_df = get_cloud_è¡Œæƒ…(target_sector)
            st.table(stocks_df)

# --- è„šæ³¨ ---
st.divider()
st.markdown("""
<div style='text-align:center; color:gray; font-size:0.8em;'>
<b>Nova æŠ•ç ”å®¡è®¡é€»è¾‘</b>ï¼š1.RSSå…¨çƒéš”ç¦»å–æ•° -> 2.ä¸“å®¶çƒ­è¯æƒé‡è¿‡æ»¤ -> 3.è·¨åŸŸè¡Œä¸šè¡Œæƒ…æ˜ å°„<br>
æœ¬ç³»ç»Ÿå·²é’ˆå¯¹ Streamlit Cloud ç¯å¢ƒè¿›è¡Œ IP å®¹é”™ä¼˜åŒ–ã€‚
</div>
""", unsafe_allow_html=True)
