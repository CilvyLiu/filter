import streamlit as st
import requests
import pandas as pd
from collections import Counter
from datetime import datetime

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="2026æ”¿ç­–çƒ­è¯ + æ¿å—å®æ—¶åˆ†æ", layout="wide")

# =========================
# 1ï¸âƒ£ æ•°æ®æŠ“å–é€»è¾‘ (ä¿æŒé«˜æ•ˆè¯·æ±‚)
# =========================
@st.cache_data(ttl=300)
def fetch_cls_news(limit=50):
    try:
        url = "https://www.cls.cn/nodeapi/telegraphs"
        # å¢åŠ ä¼ªè£…å¤´é˜²æ­¢äº‘ç«¯é˜»æ–­
        headers = {"User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers, timeout=10).json()
        items = res.get("data", {}).get("roll_data", []) # æ³¨æ„è´¢è”ç¤¾å­—æ®µç»“æ„
        if not items: items = res.get("data", [])
        
        records = []
        for item in items[:limit]:
            records.append({
                "title": item.get("title", ""),
                "content": item.get("content", ""),
                "time": datetime.fromtimestamp(item.get("ctime", 0))
            })
        return pd.DataFrame(records)
    except Exception as e:
        return pd.DataFrame()

@st.cache_data(ttl=1800)
def fetch_eastmoney_boards():
    try:
        url = ("https://push2.eastmoney.com/api/qt/clist/get?"
               "pn=1&pz=200&po=1&np=1&fltt=2&invt=2&fid=f3&fs=m:90+t:2+f:!50&fields=f12,f14,f3,f6")
        res = requests.get(url, timeout=10).json()
        data = res.get("data", {}).get("diff", [])
        if not data: return pd.DataFrame()
        df = pd.DataFrame(data).rename(columns={"f12": "code", "f14": "name", "f3": "change_pct", "f6": "amount"})
        return df
    except:
        return pd.DataFrame()

# =========================
# 2ï¸âƒ£ é€»è¾‘æ”¹å†™ï¼šåˆå¹¶å…³é”®è¯ä¾¦æµ‹
# =========================
def analyze_with_custom_keywords(news_df, manual_keyword):
    # ç¬¬ä¸€ï¼šé¢„è®¾ä¸“å®¶çº§çƒ­è¯
    expert_keywords = {
        'å›è´­æ³¨é”€': 5, 'å¸‚å€¼ç®¡ç†': 4, 'æ–°è´¨ç”Ÿäº§åŠ›': 3, 
        'ç‰¹åˆ«å›½å€º': 5, 'å¹¶è´­é‡ç»„': 4, 'ä½ç©ºç»æµ': 3
    }
    
    # ç¬¬äºŒï¼šåˆå¹¶æ‰‹åŠ¨è¾“å…¥å…³é”®è¯ (èµ‹äºˆæœ€é«˜æƒé‡)
    if manual_keyword:
        expert_keywords[manual_keyword] = 10 # æ‰‹åŠ¨è¾“å…¥è®¾ä¸ºæœ€é«˜ä¼˜å…ˆçº§
    
    def detect(text):
        content = str(text)
        found = [w for w in expert_keywords.keys() if w in content]
        score = sum([expert_keywords[w] for w in found])
        return score, ", ".join(found)

    if not news_df.empty:
        res = news_df['content'].apply(detect)
        news_df['weight'] = [x[0] for x in res]
        news_df['signals'] = [x[1] for x in res]
        return news_df[news_df['weight'] > 0].sort_values('weight', ascending=False)
    return news_df

# =========================
# 3ï¸âƒ£ UI æ¸²æŸ“å±‚
# =========================
st.title("ğŸ“Š 2026æ”¿ç­–çƒ­è¯ & æ¿å—ç©¿é€ç³»ç»Ÿ")

# ä¾§è¾¹æ ï¼šäº¤äº’è¾“å…¥
st.sidebar.header("ğŸ” æ‰‹åŠ¨å¹²é¢„é€»è¾‘")
manual_key = st.sidebar.text_input("æ‰‹åŠ¨æ³¨å…¥å…³é”®è¯ (å®æ—¶åˆå¹¶æœç´¢)", placeholder="å¦‚ï¼šå›ºæ€ç”µæ± ")

# è·å–æ•°æ®
news_df = fetch_cls_news()
boards_df = fetch_eastmoney_boards()

# ç¬¬ä¸€éƒ¨åˆ†ï¼šçƒ­è¯èåˆä¸æœç´¢
col1, col2 = st.columns([2, 1])

with col1:
    st.subheader("ğŸš© æ”¿ç­–æƒé‡çœ‹æ¿ (è‡ªåŠ¨çƒ­è¯ + æ‰‹åŠ¨æ³¨å…¥)")
    processed_news = analyze_with_custom_keywords(news_df.copy(), manual_key)
    
    if not processed_news.empty:
        for _, row in processed_news.head(10).iterrows():
            # çªå‡ºæ˜¾ç¤ºæ‰‹åŠ¨æœç´¢åˆ°çš„è¯
            is_manual = manual_key and manual_key in row['signals']
            box_type = st.error if is_manual else st.info
            box_type(f"**ã€æƒé‡: {row['weight']} | ä¿¡å·: {row['signals']}ã€‘** {row['time']}\n\n{row['content']}")
    else:
        st.info("å½“å‰æš‚æ— åŒ¹é…çš„é«˜æƒé‡ä¿¡å·ã€‚")

with col2:
    st.subheader("ğŸ­ è¡Œä¸šæ¿å—æ´»è·ƒåº¦")
    if not boards_df.empty:
        # æŒ‰ç…§æˆäº¤é¢æ’åºï¼Œæ’‡æ‰æ— æµåŠ¨æ€§çš„æ¿å—
        top_boards = boards_df.sort_values('amount', ascending=False).head(15)
        st.dataframe(top_boards[['name', 'change_pct']], hide_index=True)
    else:
        st.warning("æ¿å—æ•°æ®è·å–å—é˜»ã€‚")

# ç¬¬äºŒéƒ¨åˆ†ï¼šå¤šæºçƒ­è¯äº‘æå–
st.divider()
st.subheader("ğŸ”— å¤šæºè¯é¢‘é€è§† (è´¢è”ç¤¾ + æ¿å—å)")
if not news_df.empty:
    all_text = " ".join(news_df['content'].astype(str)) + " ".join(boards_df['name'].astype(str))
    # ç®€å•çš„è¯é¢‘è¿‡æ»¤é€»è¾‘
    stop_words = ['å…³äº', 'è¿›è¡Œ', 'å·²ç»', 'ç›®å‰', 'é€šè¿‡', 'å‘å¸ƒ']
    words = [w for w in all_text.replace('\n','').split() if len(w) > 1 and w not in stop_words]
    hot_counts = Counter(words).most_common(20)
    
    # è½¬æ¢æˆ DataFrame å±•ç¤º
    hot_df = pd.DataFrame(hot_counts, columns=['çƒ­è¯', 'é¢‘ç‡'])
    st.bar_chart(hot_df.set_index('çƒ­è¯'))

st.markdown("""
<div style='text-align:center; color:gray; font-size:0.8em;'>
ç³»ç»Ÿé€»è¾‘ï¼š[æ‰‹åŠ¨å…³é”®è¯ä¼˜å…ˆçº§10] + [ä¸“å®¶å…³é”®è¯ä¼˜å…ˆçº§3-5] -> æƒé‡åŠ æƒæ’åº<br>
Novaï¼Œå½“å‰æ¨¡å¼å·²æ’‡æ‰è¡¨é¢æº¢ä»·ï¼Œç›´å‡»æ”¿ç­–æ ¸å¿ƒã€‚
</div>
""", unsafe_allow_html=True)
